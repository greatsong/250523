import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import re
import json
from collections import Counter
import numpy as np
from openai import OpenAI
from typing import List, Dict, Optional
import time

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI ìŠ¤ë§ˆíŠ¸ ì„¤ë¬¸ ë¶„ì„ ì‹œìŠ¤í…œ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼
CUSTOM_CSS = """
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: 700;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        margin-bottom: 2rem;
    }
    .column-config {
        background-color: #f7f9fc;
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 1rem;
        border-left: 4px solid #667eea;
    }
    .metric-card {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        padding: 1.5rem;
        border-radius: 15px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        text-align: center;
        transition: all 0.3s ease;
    }
    .ai-insight-box {
        background: linear-gradient(135deg, #ffeaa7 0%, #fab1a0 100%);
        padding: 1.5rem;
        border-radius: 15px;
        margin: 1rem 0;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    .section-header {
        font-size: 1.8rem;
        font-weight: 600;
        color: #2d3748;
        margin: 2rem 0 1rem 0;
        padding-bottom: 0.5rem;
        border-bottom: 3px solid #667eea;
    }
</style>
"""

# CSS ì ìš©
st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

# ì»¬ëŸ¼ íƒ€ì… ì •ì˜
COLUMN_TYPES = {
    "timestamp": "íƒ€ì„ìŠ¤íƒ¬í”„ (ì‘ë‹µ ì‹œê°„)",
    "text_short": "ë‹¨ë‹µí˜• í…ìŠ¤íŠ¸",
    "text_long": "ì¥ë¬¸í˜• í…ìŠ¤íŠ¸",
    "email": "ì´ë©”ì¼ ì£¼ì†Œ",
    "phone": "ì „í™”ë²ˆí˜¸",
    "name": "ì´ë¦„",
    "student_id": "í•™ë²ˆ/ì‚¬ë²ˆ",
    "single_choice": "ë‹¨ì¼ ì„ íƒ (ë¼ë””ì˜¤)",
    "multiple_choice": "ë‹¤ì¤‘ ì„ íƒ (ì²´í¬ë°•ìŠ¤)",
    "linear_scale": "ì„ í˜• ì²™ë„ (1-5, 1-10 ë“±)",
    "numeric": "ìˆ«ì",
    "date": "ë‚ ì§œ",
    "time": "ì‹œê°„",
    "other": "ê¸°íƒ€"
}

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'column_configs' not in st.session_state:
    st.session_state.column_configs = {}
if 'df' not in st.session_state:
    st.session_state.df = None
if 'ai_analyses' not in st.session_state:
    st.session_state.ai_analyses = {}

class AIAnalyzer:
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)
    
    def auto_detect_column_types(self, df: pd.DataFrame) -> Dict[str, str]:
        """AIë¥¼ í™œìš©í•œ ìë™ ì»¬ëŸ¼ íƒ€ì… ê°ì§€"""
        column_samples = {}
        
        for col in df.columns:
            samples = df[col].dropna().head(5).tolist()
            column_samples[col] = {
                "samples": samples,
                "unique_count": df[col].nunique(),
                "null_count": df[col].isnull().sum()
            }
        
        prompt = f"""
        ë‹¤ìŒ ì„¤ë¬¸ ë°ì´í„°ì˜ ê° ì»¬ëŸ¼ íƒ€ì…ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.
        
        ê°€ëŠ¥í•œ íƒ€ì…:
        - timestamp: íƒ€ì„ìŠ¤íƒ¬í”„ (ë‚ ì§œ/ì‹œê°„ í˜•ì‹)
        - text_short: ë‹¨ë‹µí˜• í…ìŠ¤íŠ¸ (í‰ê·  50ì ì´í•˜)
        - text_long: ì¥ë¬¸í˜• í…ìŠ¤íŠ¸ (í‰ê·  50ì ì´ìƒ)
        - email: ì´ë©”ì¼ ì£¼ì†Œ
        - phone: ì „í™”ë²ˆí˜¸
        - name: ì´ë¦„
        - student_id: í•™ë²ˆ/ì‚¬ë²ˆ
        - single_choice: ë‹¨ì¼ ì„ íƒ (ë™ì¼í•œ ì˜µì…˜ì´ ë°˜ë³µ)
        - multiple_choice: ë‹¤ì¤‘ ì„ íƒ (ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì—¬ëŸ¬ ì˜µì…˜)
        - linear_scale: ì„ í˜• ì²™ë„ (1-5, 1-10 ë“± ìˆ«ì ë²”ìœ„)
        - numeric: ì¼ë°˜ ìˆ«ì
        - other: ê¸°íƒ€
        
        ì»¬ëŸ¼ ì •ë³´:
        {json.dumps(column_samples, ensure_ascii=False, indent=2)}
        
        JSON í˜•ì‹ìœ¼ë¡œ ê° ì»¬ëŸ¼ì˜ íƒ€ì…ì„ ë°˜í™˜í•˜ì„¸ìš”:
        {{"ì»¬ëŸ¼ëª…": "íƒ€ì…", ...}}
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"},
                temperature=0.1
            )
            
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            st.error(f"AI ì»¬ëŸ¼ íƒ€ì… ê°ì§€ ì˜¤ë¥˜: {str(e)}")
            return {}
    
    def analyze_text_sentiments(self, texts: List[str], question: str) -> Dict:
        """í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„"""
        if not texts:
            return {}
        
        # ìƒ˜í”Œë§ (ë¹„ìš© ì ˆê°ì„ ìœ„í•´ ìµœëŒ€ 30ê°œ)
        sample_texts = texts[:30] if len(texts) > 30 else texts
        
        prompt = f"""
        ì„¤ë¬¸ ì§ˆë¬¸: {question}
        
        ë‹¤ìŒ ì‘ë‹µë“¤ì˜ ê°ì •ê³¼ í†¤ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
        {json.dumps(sample_texts, ensure_ascii=False)}
        
        ë¶„ì„ í›„ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜:
        {{
            "overall_sentiment": "ë§¤ìš° ê¸ì •/ê¸ì •/ì¤‘ë¦½/ë¶€ì •/ë§¤ìš° ë¶€ì •",
            "sentiment_scores": {{"ê¸ì •": 0.0, "ì¤‘ë¦½": 0.0, "ë¶€ì •": 0.0}},
            "main_emotions": ["ê°ì •1", "ê°ì •2", "ê°ì •3"],
            "tone": "professional/casual/emotional/analytical",
            "key_concerns": ["ìš°ë ¤ì‚¬í•­1", "ìš°ë ¤ì‚¬í•­2"],
            "positive_aspects": ["ê¸ì •ì  ì¸¡ë©´1", "ê¸ì •ì  ì¸¡ë©´2"]
        }}
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"},
                temperature=0.3
            )
            
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            st.error(f"ê°ì • ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {}
    
    def extract_key_themes(self, texts: List[str], question: str) -> Dict:
        """ì£¼ìš” í…Œë§ˆ ì¶”ì¶œ"""
        if not texts:
            return {}
        
        sample_texts = texts[:50] if len(texts) > 50 else texts
        
        prompt = f"""
        ì„¤ë¬¸ ì§ˆë¬¸: {question}
        
        ë‹¤ìŒ ì‘ë‹µë“¤ì—ì„œ í•µì‹¬ ì£¼ì œì™€ íŒ¨í„´ì„ ì¶”ì¶œí•˜ì„¸ìš”:
        {json.dumps(sample_texts, ensure_ascii=False)}
        
        JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜:
        {{
            "main_themes": [
                {{"theme": "ì£¼ì œëª…", "frequency": 0.3, "description": "ì„¤ëª…"}},
                {{"theme": "ì£¼ì œëª…", "frequency": 0.25, "description": "ì„¤ëª…"}}
            ],
            "recurring_keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"],
            "unique_insights": ["ë…íŠ¹í•œ ê´€ì 1", "ë…íŠ¹í•œ ê´€ì 2"],
            "recommendations": ["ì œì•ˆì‚¬í•­1", "ì œì•ˆì‚¬í•­2"]
        }}
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"},
                temperature=0.3
            )
            
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            st.error(f"ì£¼ì œ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
            return {}
    
    def generate_executive_summary(self, analyses: Dict, df_stats: Dict) -> str:
        """ê²½ì˜ì§„ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
        prompt = f"""
        ë‹¤ìŒ ì„¤ë¬¸ì¡°ì‚¬ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²½ì˜ì§„ì„ ìœ„í•œ í•µì‹¬ ìš”ì•½ì„ ì‘ì„±í•˜ì„¸ìš”:
        
        ê¸°ë³¸ í†µê³„:
        - ì „ì²´ ì‘ë‹µ ìˆ˜: {df_stats['total_responses']}
        - í‰ê·  ì™„ë£Œìœ¨: {df_stats['completion_rate']:.1f}%
        - ì§ˆë¬¸ ìˆ˜: {df_stats['question_count']}
        
        ì£¼ìš” ë¶„ì„ ê²°ê³¼:
        {json.dumps(analyses, ensure_ascii=False, indent=2)}
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ 200-300ì ë‚´ì™¸ì˜ ìš”ì•½ì„ ì‘ì„±í•˜ì„¸ìš”:
        1. í•µì‹¬ ë°œê²¬ì‚¬í•­ (2-3ê°œ)
        2. ì£¼ìš” ì‹œì‚¬ì 
        3. ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­ (2-3ê°œ)
        
        ê°„ê²°í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ìœ„ì£¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3
            )
            
            return response.choices[0].message.content
        except Exception as e:
            return f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def analyze_response_quality(self, texts: List[str], question: str) -> Dict:
        """ì‘ë‹µ í’ˆì§ˆ í‰ê°€"""
        if not texts:
            return {}
        
        sample_texts = texts[:20] if len(texts) > 20 else texts
        
        prompt = f"""
        ì„¤ë¬¸ ì§ˆë¬¸: {question}
        
        ë‹¤ìŒ ì‘ë‹µë“¤ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ì„¸ìš”:
        {json.dumps(sample_texts, ensure_ascii=False)}
        
        í‰ê°€ ê¸°ì¤€:
        - ì™„ì„±ë„: ì¶©ì‹¤í•˜ê³  ì™„ì „í•œ ì‘ë‹µì¸ê°€
        - ê´€ë ¨ì„±: ì§ˆë¬¸ê³¼ ì§ì ‘ ê´€ë ¨ìˆëŠ”ê°€
        - êµ¬ì²´ì„±: êµ¬ì²´ì  ë‚´ìš©ì„ í¬í•¨í•˜ëŠ”ê°€
        - ìœ ìš©ì„±: ê±´ì„¤ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œê°€
        
        JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜:
        {{
            "average_quality_score": 0.75,
            "quality_breakdown": {{"ë†’ìŒ": 30, "ì¤‘ê°„": 50, "ë‚®ìŒ": 20}},
            "improvement_areas": ["ê°œì„ ì 1", "ê°œì„ ì 2"],
            "exemplary_patterns": ["ìš°ìˆ˜ íŒ¨í„´1", "ìš°ìˆ˜ íŒ¨í„´2"]
        }}
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"},
                temperature=0.3
            )
            
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            st.error(f"í’ˆì§ˆ í‰ê°€ ì˜¤ë¥˜: {str(e)}")
            return {}

def mask_sensitive_data(df: pd.DataFrame, column_configs: Dict[str, str]) -> pd.DataFrame:
    """ë¯¼ê° ì •ë³´ ë§ˆìŠ¤í‚¹"""
    masked_df = df.copy()
    
    for col, col_type in column_configs.items():
        if col_type == 'email':
            masked_df[col] = masked_df[col].apply(lambda x: x[:3] + '***@***' if pd.notna(x) and '@' in str(x) else x)
        elif col_type == 'phone':
            masked_df[col] = masked_df[col].apply(lambda x: str(x)[:3] + '-****-' + str(x)[-4:] if pd.notna(x) and len(str(x)) > 7 else x)
        elif col_type == 'name':
            masked_df[col] = masked_df[col].apply(lambda x: str(x)[0] + '*' * (len(str(x))-1) if pd.notna(x) and len(str(x)) > 0 else x)
        elif col_type == 'student_id':
            masked_df[col] = masked_df[col].apply(lambda x: str(x)[:2] + '*' * 4 + str(x)[-2:] if pd.notna(x) and len(str(x)) > 4 else x)
    
    return masked_df

def analyze_timestamp(series):
    """íƒ€ì„ìŠ¤íƒ¬í”„ ë¶„ì„"""
    try:
        # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì‹œë„
        timestamps = pd.to_datetime(series, errors='coerce')
        timestamps = timestamps.dropna()
        
        if len(timestamps) == 0:
            return None
        
        return {
            "hourly": timestamps.dt.hour.value_counts().sort_index(),
            "daily": timestamps.dt.date.value_counts().sort_index(),
            "weekday": timestamps.dt.day_name().value_counts()
        }
    except:
        return None

def main():
    # í—¤ë”
    st.markdown('<h1 class="main-header">ğŸ¤– AI ìŠ¤ë§ˆíŠ¸ ì„¤ë¬¸ ë¶„ì„ ì‹œìŠ¤í…œ</h1>', unsafe_allow_html=True)
    st.markdown('<p style="text-align: center; color: #718096; margin-bottom: 2rem;">AIê°€ ì„¤ë¬¸ ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤</p>', unsafe_allow_html=True)
    
    # ì‚¬ì´ë“œë°”ì— API í‚¤ ì…ë ¥
    with st.sidebar:
        st.markdown("### âš™ï¸ ì„¤ì •")
        
        # OpenAI API í‚¤ (Streamlit Secrets ìš°ì„ , ì—†ìœ¼ë©´ ì…ë ¥ë°›ê¸°)
        api_key = st.secrets.get("OPENAI_API_KEY", "")
        if not api_key:
            api_key = st.text_input("OpenAI API Key", type="password", help="sk-ë¡œ ì‹œì‘í•˜ëŠ” API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        
        if api_key:
            st.success("âœ… API í‚¤ ì„¤ì •ë¨")
        else:
            st.warning("âš ï¸ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        st.markdown("---")
        
        # ë°ì´í„° ë³´í˜¸ ì˜µì…˜
        mask_sensitive = st.checkbox("ğŸ”’ ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹", value=True)
        use_ai_detection = st.checkbox("ğŸ¤– AI ìë™ ì»¬ëŸ¼ ê°ì§€", value=True)
    
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader(
        "CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=['csv'],
        help="Google Formsë‚˜ ë‹¤ë¥¸ ì„¤ë¬¸ í”Œë«í¼ì—ì„œ ë‚´ë³´ë‚¸ CSV íŒŒì¼"
    )
    
    if uploaded_file is not None:
        try:
            # ë°ì´í„° ë¡œë“œ
            df = pd.read_csv(uploaded_file, encoding='utf-8')
            st.session_state.df = df
            
            st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ! (ì‘ë‹µ {len(df)}ê°œ, ì§ˆë¬¸ {len(df.columns)}ê°œ)")
            
            # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
            with st.expander("ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", expanded=False):
                display_df = mask_sensitive_data(df, st.session_state.column_configs) if mask_sensitive else df
                st.dataframe(display_df.head(10))
            
            # ì»¬ëŸ¼ íƒ€ì… ì„¤ì •
            st.markdown('<h2 class="section-header">âš™ï¸ ì»¬ëŸ¼ íƒ€ì… ì„¤ì •</h2>', unsafe_allow_html=True)
            
            # AI ìë™ ê°ì§€
            if use_ai_detection and api_key and not st.session_state.column_configs:
                with st.spinner("ğŸ¤– AIê°€ ì»¬ëŸ¼ íƒ€ì…ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    ai_analyzer = AIAnalyzer(api_key)
                    detected_types = ai_analyzer.auto_detect_column_types(df)
                    
                    if detected_types:
                        st.session_state.column_configs = detected_types
                        st.success("âœ… AIê°€ ì»¬ëŸ¼ íƒ€ì…ì„ ìë™ìœ¼ë¡œ ê°ì§€í–ˆìŠµë‹ˆë‹¤!")
            
            # ì»¬ëŸ¼ ì„¤ì • UI
            col1, col2 = st.columns([1, 1])
            
            for i, column in enumerate(df.columns):
                with col1 if i % 2 == 0 else col2:
                    with st.container():
                        st.markdown(f'<div class="column-config">', unsafe_allow_html=True)
                        st.markdown(f"**{column}**")
                        
                        # ìƒ˜í”Œ ë°ì´í„°
                        sample_data = df[column].dropna().head(3).tolist()
                        if sample_data:
                            sample_text = ', '.join([str(x)[:30] + '...' if len(str(x)) > 30 else str(x) for x in sample_data])
                            st.caption(f"ì˜ˆì‹œ: {sample_text}")
                        
                        # íƒ€ì… ì„ íƒ
                        current_type = st.session_state.column_configs.get(column, "other")
                        selected_type = st.selectbox(
                            "íƒ€ì…",
                            options=list(COLUMN_TYPES.keys()),
                            format_func=lambda x: COLUMN_TYPES[x],
                            key=f"col_type_{column}",
                            index=list(COLUMN_TYPES.keys()).index(current_type)
                        )
                        
                        st.session_state.column_configs[column] = selected_type
                        st.markdown('</div>', unsafe_allow_html=True)
            
            # ë¶„ì„ ì‹¤í–‰
            if st.button("ğŸš€ ë¶„ì„ ì‹œì‘", use_container_width=True, type="primary"):
                analyze_survey(df, st.session_state.column_configs, api_key, mask_sensitive)
            
        except Exception as e:
            st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            st.info("UTF-8 ì¸ì½”ë”©ì˜ CSV íŒŒì¼ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")

def analyze_survey(df: pd.DataFrame, column_configs: Dict[str, str], api_key: str, mask_sensitive: bool):
    """ì„¤ë¬¸ ë¶„ì„ ì‹¤í–‰"""
    
    # íƒ­ ìƒì„±
    tabs = st.tabs(["ğŸ“Š ê°œìš”", "ğŸ“ˆ í†µê³„ ë¶„ì„", "ğŸ¤– AI ì¸ì‚¬ì´íŠ¸", "ğŸ’¬ í…ìŠ¤íŠ¸ ë¶„ì„", "ğŸ“¥ ë³´ê³ ì„œ"])
    
    # AI ë¶„ì„ê¸° ì´ˆê¸°í™”
    ai_analyzer = AIAnalyzer(api_key) if api_key else None
    
    # ê¸°ë³¸ í†µê³„
    df_stats = {
        'total_responses': len(df),
        'question_count': len(df.columns),
        'completion_rate': (df.notna().sum().sum() / (len(df) * len(df.columns))) * 100
    }
    
    with tabs[0]:  # ê°œìš”
        st.markdown('<h2 class="section-header">ğŸ“Š ì „ì²´ ê°œìš”</h2>', unsafe_allow_html=True)
        
        # ë©”íŠ¸ë¦­ ì¹´ë“œ
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
            st.metric("ì „ì²´ ì‘ë‹µ", f"{df_stats['total_responses']}ê°œ")
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
            st.metric("ì§ˆë¬¸ ìˆ˜", f"{df_stats['question_count']}ê°œ")
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col3:
            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
            st.metric("í‰ê·  ì™„ë£Œìœ¨", f"{df_stats['completion_rate']:.1f}%")
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col4:
            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
            null_rate = (df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100
            st.metric("ë¯¸ì‘ë‹µë¥ ", f"{null_rate:.1f}%")
            st.markdown('</div>', unsafe_allow_html=True)
        
        # ì‘ë‹µë¥  ì°¨íŠ¸
        st.markdown("### ğŸ“Š ì§ˆë¬¸ë³„ ì‘ë‹µë¥ ")
        response_rates = (df.notna().sum() / len(df) * 100).sort_values(ascending=True)
        
        fig = px.bar(
            x=response_rates.values,
            y=response_rates.index,
            orientation='h',
            labels={'x': 'ì‘ë‹µë¥  (%)', 'y': 'ì§ˆë¬¸'},
            color=response_rates.values,
            color_continuous_scale='viridis'
        )
        fig.update_layout(height=max(400, len(response_rates) * 25))
        st.plotly_chart(fig, use_container_width=True)
    
    with tabs[1]:  # í†µê³„ ë¶„ì„
        st.markdown('<h2 class="section-header">ğŸ“ˆ í†µê³„ ë¶„ì„</h2>', unsafe_allow_html=True)
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ë¶„ì„
        timestamp_cols = [col for col, typ in column_configs.items() if typ == 'timestamp']
        if timestamp_cols:
            st.markdown("### â° ì‹œê°„ ë¶„ì„")
            ts_col = timestamp_cols[0]
            ts_data = analyze_timestamp(df[ts_col])
            
            if ts_data:
                col1, col2 = st.columns(2)
                
                with col1:
                    fig = px.bar(
                        x=ts_data['hourly'].index,
                        y=ts_data['hourly'].values,
                        labels={'x': 'ì‹œê°„', 'y': 'ì‘ë‹µ ìˆ˜'},
                        title="ì‹œê°„ëŒ€ë³„ ì‘ë‹µ ë¶„í¬"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                with col2:
                    fig = px.line(
                        x=ts_data['daily'].index,
                        y=ts_data['daily'].values,
                        labels={'x': 'ë‚ ì§œ', 'y': 'ì‘ë‹µ ìˆ˜'},
                        title="ì¼ë³„ ì‘ë‹µ ì¶”ì´",
                        markers=True
                    )
                    st.plotly_chart(fig, use_container_width=True)
        
        # ì„ íƒí˜• ì§ˆë¬¸ ë¶„ì„
        choice_cols = [col for col, typ in column_configs.items() if typ in ['single_choice', 'multiple_choice']]
        
        if choice_cols:
            st.markdown("### ğŸ“Š ì„ íƒí˜• ì§ˆë¬¸")
            
            for col in choice_cols[:5]:  # ìƒìœ„ 5ê°œë§Œ
                st.markdown(f"#### {col}")
                
                if column_configs[col] == 'multiple_choice':
                    # ë‹¤ì¤‘ ì„ íƒ ì²˜ë¦¬
                    all_values = []
                    for val in df[col].dropna():
                        all_values.extend([v.strip() for v in str(val).split(',')])
                    value_counts = pd.Series(all_values).value_counts()
                else:
                    value_counts = df[col].value_counts()
                
                col1, col2 = st.columns(2)
                
                with col1:
                    fig = px.pie(
                        values=value_counts.values[:10],
                        names=value_counts.index[:10],
                        title="ì‘ë‹µ ë¶„í¬"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                with col2:
                    fig = px.bar(
                        x=value_counts.values[:10],
                        y=value_counts.index[:10],
                        orientation='h',
                        labels={'x': 'ì‘ë‹µ ìˆ˜', 'y': 'ì„ íƒì§€'}
                    )
                    st.plotly_chart(fig, use_container_width=True)
    
    with tabs[2]:  # AI ì¸ì‚¬ì´íŠ¸
        st.markdown('<h2 class="section-header">ğŸ¤– AI ì¸ì‚¬ì´íŠ¸</h2>', unsafe_allow_html=True)
        
        if not api_key:
            st.warning("âš ï¸ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            st.info("ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ Streamlit Secretsì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        else:
            # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì°¾ê¸°
            text_cols = [col for col, typ in column_configs.items() if typ in ['text_short', 'text_long']]
            
            if text_cols:
                # ë¶„ì„í•  ì»¬ëŸ¼ ì„ íƒ
                selected_col = st.selectbox("ë¶„ì„í•  í…ìŠ¤íŠ¸ ì§ˆë¬¸ ì„ íƒ", text_cols)
                
                if st.button("ğŸ” AI ë¶„ì„ ì‹¤í–‰"):
                    texts = df[selected_col].dropna().tolist()
                    
                    if texts:
                        with st.spinner("ğŸ¤– AIê°€ ì‘ë‹µì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                            # ê°ì • ë¶„ì„
                            sentiment_result = ai_analyzer.analyze_text_sentiments(texts, selected_col)
                            
                            if sentiment_result:
                                st.markdown("### ğŸ˜Š ê°ì • ë¶„ì„")
                                
                                col1, col2, col3 = st.columns(3)
                                
                                with col1:
                                    st.metric("ì „ë°˜ì  ê°ì •", sentiment_result.get('overall_sentiment', 'N/A'))
                                
                                with col2:
                                    st.metric("ì£¼ìš” í†¤", sentiment_result.get('tone', 'N/A'))
                                
                                with col3:
                                    emotions = sentiment_result.get('main_emotions', [])
                                    st.metric("ì£¼ìš” ê°ì •", ', '.join(emotions[:3]) if emotions else 'N/A')
                                
                                # ê°ì • ë¶„í¬
                                if 'sentiment_scores' in sentiment_result:
                                    fig = px.pie(
                                        values=list(sentiment_result['sentiment_scores'].values()),
                                        names=list(sentiment_result['sentiment_scores'].keys()),
                                        title="ê°ì • ë¶„í¬"
                                    )
                                    st.plotly_chart(fig, use_container_width=True)
                            
                            # ì£¼ì œ ë¶„ì„
                            theme_result = ai_analyzer.extract_key_themes(texts, selected_col)
                            
                            if theme_result:
                                st.markdown("### ğŸ¯ ì£¼ìš” í…Œë§ˆ")
                                
                                if 'main_themes' in theme_result:
                                    for theme in theme_result['main_themes'][:5]:
                                        st.markdown(f"**{theme['theme']}** ({theme['frequency']*100:.0f}%)")
                                        st.caption(theme.get('description', ''))
                                
                                if 'recommendations' in theme_result:
                                    st.markdown("### ğŸ’¡ AI ì œì•ˆì‚¬í•­")
                                    for rec in theme_result['recommendations']:
                                        st.info(f"â€¢ {rec}")
                            
                            # í’ˆì§ˆ í‰ê°€
                            quality_result = ai_analyzer.analyze_response_quality(texts, selected_col)
                            
                            if quality_result:
                                st.markdown("### ğŸ“Š ì‘ë‹µ í’ˆì§ˆ")
                                
                                avg_score = quality_result.get('average_quality_score', 0)
                                st.metric("í‰ê·  í’ˆì§ˆ ì ìˆ˜", f"{avg_score:.2f} / 1.0")
                                
                                if 'quality_breakdown' in quality_result:
                                    fig = px.bar(
                                        x=list(quality_result['quality_breakdown'].keys()),
                                        y=list(quality_result['quality_breakdown'].values()),
                                        labels={'x': 'í’ˆì§ˆ ìˆ˜ì¤€', 'y': 'ì‘ë‹µ ë¹„ìœ¨ (%)'},
                                        title="ì‘ë‹µ í’ˆì§ˆ ë¶„í¬"
                                    )
                                    st.plotly_chart(fig, use_container_width=True)
                                
                                # AI ë¶„ì„ ê²°ê³¼ ì €ì¥
                                st.session_state.ai_analyses[selected_col] = {
                                    'sentiment': sentiment_result,
                                    'themes': theme_result,
                                    'quality': quality_result
                                }
            else:
                st.info("í…ìŠ¤íŠ¸ í˜•ì‹ì˜ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë¶„ì„ì„ ì§„í–‰í•´ë³´ì„¸ìš”.")
            
            # ê²½ì˜ì§„ ìš”ì•½
            if st.session_state.ai_analyses:
                st.markdown("### ğŸ“‹ AI ê²½ì˜ì§„ ìš”ì•½")
                
                if st.button("ğŸ“„ ì¢…í•© ìš”ì•½ ìƒì„±"):
                    with st.spinner("ìš”ì•½ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                        summary = ai_analyzer.generate_executive_summary(
                            st.session_state.ai_analyses,
                            df_stats
                        )
                        
                        st.markdown('<div class="ai-insight-box">', unsafe_allow_html=True)
                        st.markdown("#### ğŸ¯ ê²½ì˜ì§„ì„ ìœ„í•œ í•µì‹¬ ìš”ì•½")
                        st.write(summary)
                        st.markdown('</div>', unsafe_allow_html=True)
    
    with tabs[3]:  # í…ìŠ¤íŠ¸ ë¶„ì„
        st.markdown('<h2 class="section-header">ğŸ’¬ í…ìŠ¤íŠ¸ ë¶„ì„</h2>', unsafe_allow_html=True)
        
        text_cols = [col for col, typ in column_configs.items() if typ in ['text_short', 'text_long']]
        
        if text_cols:
            for col in text_cols:
                st.markdown(f"### ğŸ“ {col}")
                
                texts = df[col].dropna()
                
                if len(texts) > 0:
                    # ê¸°ë³¸ í†µê³„
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("ì‘ë‹µ ìˆ˜", f"{len(texts)}ê°œ")
                    
                    with col2:
                        avg_length = texts.str.len().mean()
                        st.metric("í‰ê·  ê¸¸ì´", f"{avg_length:.0f}ì")
                    
                    with col3:
                        st.metric("ìµœì†Œ ê¸¸ì´", f"{texts.str.len().min()}ì")
                    
                    with col4:
                        st.metric("ìµœëŒ€ ê¸¸ì´", f"{texts.str.len().max()}ì")
                    
                    # ë‹¨ì–´ ë¹ˆë„ ë¶„ì„
                    all_text = ' '.join(texts.astype(str))
                    words = re.findall(r'[ê°€-í£]+|[a-zA-Z]+', all_text.lower())
                    
                    # ë¶ˆìš©ì–´ ì œê±°
                    stopwords = {'ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì˜', 'ì—', 'ì™€', 'ê³¼', 'ë„', 'ë¡œ', 'ìœ¼ë¡œ', 'ë§Œ', 'ì—ì„œ', 'ê¹Œì§€', 'ë¶€í„°', 'ë¼ê³ ', 'í•˜ê³ ', 'ìˆë‹¤', 'ìˆëŠ”', 'ìˆê³ ', 'í•©ë‹ˆë‹¤', 'ì…ë‹ˆë‹¤', 'ë©ë‹ˆë‹¤'}
                    words = [w for w in words if w not in stopwords and len(w) > 1]
                    
                    if words:
                        word_freq = Counter(words).most_common(15)
                        
                        st.markdown("#### ğŸ”¤ ì£¼ìš” í‚¤ì›Œë“œ")
                        
                        fig = px.bar(
                            x=[w[1] for w in word_freq],
                            y=[w[0] for w in word_freq],
                            orientation='h',
                            labels={'x': 'ë¹ˆë„', 'y': 'ë‹¨ì–´'},
                            color=[w[1] for w in word_freq],
                            color_continuous_scale='blues'
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # ìƒ˜í”Œ ì‘ë‹µ
                    st.markdown("#### ğŸ’¬ ìƒ˜í”Œ ì‘ë‹µ")
                    sample_size = min(5, len(texts))
                    samples = texts.sample(sample_size)
                    
                    for i, text in enumerate(samples, 1):
                        with st.expander(f"ì‘ë‹µ {i}"):
                            st.write(text)
        else:
            st.info("í…ìŠ¤íŠ¸ í˜•ì‹ì˜ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    with tabs[4]:  # ë³´ê³ ì„œ
        st.markdown('<h2 class="section-header">ğŸ“¥ ë¶„ì„ ë³´ê³ ì„œ</h2>', unsafe_allow_html=True)
        
        # ë³´ê³ ì„œ ì˜µì…˜
        st.markdown("### ğŸ“‹ ë³´ê³ ì„œ ìƒì„± ì˜µì…˜")
        
        report_type = st.selectbox(
            "ë³´ê³ ì„œ í˜•ì‹",
            ["ê¸°ë³¸ í†µê³„ ë³´ê³ ì„œ", "AI ë¶„ì„ ë³´ê³ ì„œ", "ì „ì²´ ì¢…í•© ë³´ê³ ì„œ"]
        )
        
        include_charts = st.checkbox("ì°¨íŠ¸ í¬í•¨", value=True)
        include_raw_data = st.checkbox("ì›ë³¸ ë°ì´í„° í¬í•¨", value=False)
        
        if st.button("ğŸ“„ ë³´ê³ ì„œ ìƒì„±", use_container_width=True):
            report = generate_report(
                df, 
                column_configs, 
                df_stats, 
                st.session_state.ai_analyses,
                report_type,
                mask_sensitive
            )
            
            st.markdown("### ğŸ“„ ìƒì„±ëœ ë³´ê³ ì„œ")
            st.text_area("ë³´ê³ ì„œ ë‚´ìš©", report, height=400)
            
            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            st.download_button(
                label="ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ (TXT)",
                data=report,
                file_name=f'survey_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.txt',
                mime='text/plain'
            )
            
            # CSV ë‹¤ìš´ë¡œë“œ
            if include_raw_data:
                if mask_sensitive:
                    download_df = mask_sensitive_data(df, column_configs)
                else:
                    download_df = df
                
                csv = download_df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
                    data=csv,
                    file_name=f'survey_data_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                    mime='text/csv'
                )

def generate_report(df, column_configs, df_stats, ai_analyses, report_type, mask_sensitive):
    """ë³´ê³ ì„œ ìƒì„±"""
    report = f"""
{'='*60}
ì„¤ë¬¸ ë¶„ì„ ë³´ê³ ì„œ
{'='*60}
ìƒì„±ì¼ì‹œ: {datetime.now().strftime("%Yë…„ %mì›” %dì¼ %H:%M:%S")}
ë³´ê³ ì„œ ìœ í˜•: {report_type}
ê°œì¸ì •ë³´ ë³´í˜¸: {'ì ìš©ë¨' if mask_sensitive else 'ë¯¸ì ìš©'}

1. ê¸°ë³¸ ì •ë³´
{'='*60}
- ì „ì²´ ì‘ë‹µ ìˆ˜: {df_stats['total_responses']}ê°œ
- ì§ˆë¬¸ ìˆ˜: {df_stats['question_count']}ê°œ
- í‰ê·  ì™„ë£Œìœ¨: {df_stats['completion_rate']:.1f}%
- ìˆ˜ì§‘ ê¸°ê°„: {df.iloc[0, 0]} ~ {df.iloc[-1, 0]}

2. ì»¬ëŸ¼ êµ¬ì„±
{'='*60}
"""
    
    # ì»¬ëŸ¼ íƒ€ì…ë³„ ê°œìˆ˜
    type_counts = Counter(column_configs.values())
    for col_type, count in type_counts.most_common():
        report += f"- {COLUMN_TYPES[col_type]}: {count}ê°œ\n"
    
    report += f"\n3. ìƒì„¸ ì»¬ëŸ¼ ì •ë³´\n{'='*60}\n"
    for col, col_type in column_configs.items():
        response_rate = (df[col].notna().sum() / len(df)) * 100
        report += f"- {col}\n"
        report += f"  íƒ€ì…: {COLUMN_TYPES[col_type]}\n"
        report += f"  ì‘ë‹µë¥ : {response_rate:.1f}%\n"
        
        if col_type in ['single_choice', 'multiple_choice']:
            top_values = df[col].value_counts().head(3)
            report += f"  ìƒìœ„ ì‘ë‹µ: {', '.join([f'{v}({c})' for v, c in top_values.items()])}\n"
        
        report += "\n"
    
    # AI ë¶„ì„ ê²°ê³¼
    if report_type in ["AI ë¶„ì„ ë³´ê³ ì„œ", "ì „ì²´ ì¢…í•© ë³´ê³ ì„œ"] and ai_analyses:
        report += f"\n4. AI ë¶„ì„ ê²°ê³¼\n{'='*60}\n"
        
        for col, analyses in ai_analyses.items():
            report += f"\n[{col}]\n{'-'*40}\n"
            
            if 'sentiment' in analyses and analyses['sentiment']:
                sentiment = analyses['sentiment']
                report += f"ê°ì • ë¶„ì„:\n"
                report += f"- ì „ë°˜ì  ê°ì •: {sentiment.get('overall_sentiment', 'N/A')}\n"
                report += f"- ì£¼ìš” ê°ì •: {', '.join(sentiment.get('main_emotions', []))}\n"
                report += f"- í†¤: {sentiment.get('tone', 'N/A')}\n\n"
            
            if 'themes' in analyses and analyses['themes']:
                themes = analyses['themes']
                report += f"ì£¼ìš” í…Œë§ˆ:\n"
                for theme in themes.get('main_themes', [])[:3]:
                    report += f"- {theme['theme']} ({theme['frequency']*100:.0f}%)\n"
                report += f"\nAI ì œì•ˆì‚¬í•­:\n"
                for rec in themes.get('recommendations', []):
                    report += f"- {rec}\n"
                report += "\n"
            
            if 'quality' in analyses and analyses['quality']:
                quality = analyses['quality']
                report += f"ì‘ë‹µ í’ˆì§ˆ:\n"
                report += f"- í‰ê·  ì ìˆ˜: {quality.get('average_quality_score', 0):.2f}/1.0\n"
                report += "\n"
    
    # ì£¼ìš” ë°œê²¬ì‚¬í•­
    if report_type == "ì „ì²´ ì¢…í•© ë³´ê³ ì„œ":
        report += f"\n5. ì£¼ìš” ë°œê²¬ì‚¬í•­ ë° ì œì•ˆ\n{'='*60}\n"
        
        # ì‘ë‹µë¥ ì´ ë‚®ì€ ì§ˆë¬¸
        low_response_cols = []
        for col in df.columns:
            response_rate = (df[col].notna().sum() / len(df)) * 100
            if response_rate < 70:
                low_response_cols.append((col, response_rate))
        
        if low_response_cols:
            report += "\në‚®ì€ ì‘ë‹µë¥  ì§ˆë¬¸:\n"
            for col, rate in sorted(low_response_cols, key=lambda x: x[1])[:5]:
                report += f"- {col}: {rate:.1f}%\n"
            report += "\nâ†’ í•´ë‹¹ ì§ˆë¬¸ë“¤ì˜ í•„ìˆ˜ ì—¬ë¶€ë‚˜ ì§ˆë¬¸ ë°©ì‹ ì¬ê²€í†  í•„ìš”\n"
        
        # í…ìŠ¤íŠ¸ ì‘ë‹µ ë¶„ì„
        text_cols = [col for col, typ in column_configs.items() if typ in ['text_short', 'text_long']]
        if text_cols:
            report += f"\ní…ìŠ¤íŠ¸ ì‘ë‹µ ì§ˆë¬¸ ({len(text_cols)}ê°œ):\n"
            for col in text_cols:
                avg_length = df[col].str.len().mean()
                report += f"- {col}: í‰ê·  {avg_length:.0f}ì\n"
    
    report += f"\n{'='*60}\në³´ê³ ì„œ ë\n{'='*60}\n"
    
    return report

# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    main()
