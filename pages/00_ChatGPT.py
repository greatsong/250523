# file: ai_smart_survey.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  í•„ìš”í•œ íŒ¨í‚¤ì§€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import koreanize_matplotlib          # ì‚¬ìš©ìì˜ ê³ ì • ìš”êµ¬
import re, json, textwrap
from datetime import datetime
from collections import Counter
from typing import Dict, List
from openai import OpenAI

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  í˜ì´ì§€ ì„¤ì •  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="AI ìŠ¤ë§ˆíŠ¸ ì„¤ë¬¸ ë¶„ì„ ì‹œìŠ¤í…œ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  CSS  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CUSTOM_CSS = """
<style>
    .main-header {font-size:2.5rem;font-weight:700;
        background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);
        -webkit-background-clip:text;-webkit-text-fill-color:transparent;
        text-align:center;margin-bottom:2rem;}
    .column-config{background:#f7f9fc;padding:1rem;border-radius:10px;
        margin-bottom:1rem;border-left:4px solid #667eea;}
    .metric-card{background:linear-gradient(135deg,#f5f7fa 0%,#c3cfe2 100%);
        padding:1.5rem;border-radius:15px;box-shadow:0 4px 15px rgba(0,0,0,0.1);
        text-align:center;transition:.3s;}
    .ai-insight-box{background:linear-gradient(135deg,#ffeaa7 0%,#fab1a0 100%);
        padding:1.5rem;border-radius:15px;margin:1rem 0;
        box-shadow:0 4px 15px rgba(0,0,0,0.1);}
    .section-header{font-size:1.8rem;font-weight:600;color:#2d3748;
        margin:2rem 0 1rem 0;padding-bottom:.5rem;border-bottom:3px solid #667eea;}
</style>
"""
st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ìƒìˆ˜  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
COLUMN_TYPES = {
    "timestamp":"íƒ€ì„ìŠ¤íƒ¬í”„ (ì‘ë‹µ ì‹œê°„)","text_short":"ë‹¨ë‹µí˜• í…ìŠ¤íŠ¸","text_long":"ì¥ë¬¸í˜• í…ìŠ¤íŠ¸",
    "email":"ì´ë©”ì¼ ì£¼ì†Œ","phone":"ì „í™”ë²ˆí˜¸","name":"ì´ë¦„","student_id":"í•™ë²ˆ/ì‚¬ë²ˆ",
    "single_choice":"ë‹¨ì¼ ì„ íƒ (ë¼ë””ì˜¤)","multiple_choice":"ë‹¤ì¤‘ ì„ íƒ (ì²´í¬ë°•ìŠ¤)",
    "linear_scale":"ì„ í˜• ì²™ë„","numeric":"ìˆ«ì","date":"ë‚ ì§œ","time":"ì‹œê°„","other":"ê¸°íƒ€"
}

STOPWORDS_KO = {'ì€','ëŠ”','ì´','ê°€','ì„','ë¥¼','ì˜','ì—','ì™€','ê³¼','ë„','ë¡œ','ìœ¼ë¡œ','ë§Œ',
                'ì—ì„œ','ê¹Œì§€','ë¶€í„°','ë¼ê³ ','í•˜ê³ ','ìˆë‹¤','ìˆëŠ”','ìˆê³ ',
                'í•©ë‹ˆë‹¤','ì…ë‹ˆë‹¤','ë©ë‹ˆë‹¤'}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ì„¸ì…˜ ì´ˆê¸°í™”  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for key,default in [("df",None),("column_configs",{}),("ai_analyses",{})]:
    if key not in st.session_state: st.session_state[key]=default

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  AI Analyzer  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class AIAnalyzer:
    """OpenAI APIë¥¼ í™œìš©í•œ ê³ ê¸‰ ë¶„ì„ê¸°"""
    def __init__(self, api_key:str):
        self.client = OpenAI(api_key=api_key)
        self.model_chat = "gpt-4o"
    # ---------- 1. ì»¬ëŸ¼ íƒ€ì… ìë™ ì¶”ë¡  ----------
    def auto_detect_column_types(self, df:pd.DataFrame) -> Dict[str,str]:
        sample_csv = df.head(3).to_csv(index=False)
        col_stats  = {c:{"unique":int(df[c].nunique()),
                         "null":int(df[c].isna().sum())} for c in df.columns}
        sys = (
            "You are a data scientist. Infer the semantic data type for each CSV column.\n"
            "Types: timestamp,email,phone,name,student_id,numeric,"
            "single_choice,multiple_choice,linear_scale,text_short,text_long,other.\n"
            "Return ONLY JSON: {\"column\":\"type\",...}"
        )
        user = f"Sample CSV (3 rows):\n{sample_csv}\n\nStats:\n{json.dumps(col_stats,ensure_ascii=False)}"
        try:
            res = self.client.chat.completions.create(
                model=self.model_chat,
                messages=[{"role":"system","content":sys},{"role":"user","content":user}],
                temperature=0
            ).choices[0].message.content.strip()
            res = re.sub(r"^```json|```$", "", res, flags=re.I).strip()
            parsed = json.loads(res)
            return {c:(parsed.get(c,"other") if parsed.get(c) in COLUMN_TYPES else "other")
                    for c in df.columns}
        except Exception as e:
            st.warning(f"GPT íƒ€ì… ì¶”ë¡  ì‹¤íŒ¨, rule-based ë¡œ ëŒ€ì²´: {e}")
            rb={}
            for c in df.columns:
                s=str(df[c].dropna().iloc[0]) if not df[c].dropna().empty else ""
                if re.fullmatch(r"\d{4}[-/]\d{1,2}[-/]\d{1,2}",s): rb[c]="date"
                elif "@" in s: rb[c]="email"
                elif re.fullmatch(r"\d{1,2}:\d{2}",s): rb[c]="time"
                elif s.isdigit(): rb[c]="numeric"
                else: rb[c]="other"
            return rb
    # ---------- 2. ê°ì • ë¶„ì„ ----------
    def analyze_text_sentiments(self,texts:List[str],question:str)->Dict:
        if not texts: return {}
        sample=texts[:30]
        prompt=textwrap.dedent(f"""
            ì„¤ë¬¸ ì§ˆë¬¸: {question}
            ë‹¤ìŒ ì‘ë‹µë“¤ì˜ ê°ì •ãƒ»í†¤ì„ ë¶„ì„í•˜ê³  JSON ë°˜í™˜:
            {json.dumps(sample,ensure_ascii=False)}
            {{
              "overall_sentiment":"ë§¤ìš° ê¸ì •/ê¸ì •/ì¤‘ë¦½/ë¶€ì •/ë§¤ìš° ë¶€ì •",
              "sentiment_scores":{{"ê¸ì •":0.0,"ì¤‘ë¦½":0.0,"ë¶€ì •":0.0}},
              "main_emotions":["ê°ì •1","ê°ì •2"],
              "tone":"professional/casual/emotional/analytical",
              "key_concerns":["ìš°ë ¤1"],
              "positive_aspects":["ì¥ì 1"]
            }}
        """)
        try:
            res=self.client.chat.completions.create(
                model=self.model_chat,messages=[{"role":"user","content":prompt}],
                temperature=0.3
            ).choices[0].message.content.strip()
            res=re.sub(r"^```json|```$","",res,flags=re.I).strip()
            return json.loads(res)
        except Exception as e:
            st.error(f"ê°ì • ë¶„ì„ ì˜¤ë¥˜: {e}"); return {}
    # ---------- 3. ì£¼ìš” í…Œë§ˆ ----------
    def extract_key_themes(self,texts:List[str],question:str)->Dict:
        if not texts: return {}
        sample=texts[:50]
        prompt=textwrap.dedent(f"""
            ì„¤ë¬¸ ì§ˆë¬¸: {question}
            ë‹¤ìŒ ì‘ë‹µì—ì„œ í•µì‹¬ ì£¼ì œÂ·í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ JSON ë°˜í™˜:
            {json.dumps(sample,ensure_ascii=False)}
            {{
               "main_themes":[
                 {{"theme":"ì£¼ì œ","frequency":0.3,"description":"..."}}
               ],
               "recurring_keywords":["í‚¤ì›Œë“œ1","í‚¤ì›Œë“œ2"],
               "unique_insights":["ì¸ì‚¬ì´íŠ¸1"],
               "recommendations":["ì œì•ˆ1"]
            }}
        """)
        try:
            res=self.client.chat.completions.create(
                model=self.model_chat,messages=[{"role":"user","content":prompt}],
                temperature=0.3
            ).choices[0].message.content.strip()
            res=re.sub(r"^```json|```$","",res,flags=re.I).strip()
            return json.loads(res)
        except Exception as e:
            st.error(f"í…Œë§ˆ ì¶”ì¶œ ì˜¤ë¥˜: {e}"); return {}
    # ---------- 4. ì‘ë‹µ í’ˆì§ˆ ----------
    def analyze_response_quality(self,texts:List[str],question:str)->Dict:
        if not texts: return {}
        sample=texts[:20]
        prompt=textwrap.dedent(f"""
            ì„¤ë¬¸ ì§ˆë¬¸: {question}
            ë‹¤ìŒ ì‘ë‹µë“¤ì˜ í’ˆì§ˆì„ í‰ê°€í•´ JSON ë°˜í™˜:
            {json.dumps(sample,ensure_ascii=False)}
            {{
             "average_quality_score":0.8,
             "quality_breakdown":{{"ë†’ìŒ":30,"ì¤‘ê°„":50,"ë‚®ìŒ":20}},
             "improvement_areas":["ê°œì„ ì 1"],
             "exemplary_patterns":["ìš°ìˆ˜ íŒ¨í„´1"]
            }}
        """)
        try:
            res=self.client.chat.completions.create(
                model=self.model_chat,messages=[{"role":"user","content":prompt}],
                temperature=0.3
            ).choices[0].message.content.strip()
            res=re.sub(r"^```json|```$","",res,flags=re.I).strip()
            return json.loads(res)
        except Exception as e:
            st.error(f"í’ˆì§ˆ í‰ê°€ ì˜¤ë¥˜: {e}"); return {}
    # ---------- 5. ê²½ì˜ì§„ ìš”ì•½ ----------
    def generate_executive_summary(self,analyses:Dict,stats:Dict)->str:
        prompt=textwrap.dedent(f"""
            ì•„ë˜ ì„¤ë¬¸ í†µê³„ì™€ AI ë¶„ì„ ê²°ê³¼ë¥¼ 200~300ì ìš”ì•½:
            í†µê³„: {stats}
            ë¶„ì„: {json.dumps(analyses,ensure_ascii=False)[:4000]}
            1) í•µì‹¬ ë°œê²¬ 2~3ê°œ, 2) ì‹œì‚¬ì , 3) ê¶Œì¥ ì¡°ì¹˜ 2~3ê°œ
        """)
        try:
            return self.client.chat.completions.create(
                model=self.model_chat,messages=[{"role":"user","content":prompt}],
                temperature=0.3
            ).choices[0].message.content.strip()
        except Exception as e:
            return f"ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ë³´ì¡° í•¨ìˆ˜  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def mask_sensitive_data(df:pd.DataFrame,configs:Dict[str,str])->pd.DataFrame:
    m=df.copy()
    for col,typ in configs.items():
        if typ=="email":
            m[col]=m[col].apply(lambda x: re.sub(r"(^..).+(@.*)","\\1***\\2",str(x))
                                if pd.notna(x) else x)
        elif typ=="phone":
            m[col]=m[col].apply(lambda x: re.sub(r"(^\d{3})\d*(\d{4}$)","\\1-****-\\2",str(x))
                                if pd.notna(x) else x)
        elif typ=="name":
            m[col]=m[col].apply(lambda x: x[0]+"*"*(len(x)-1) if pd.notna(x) and len(str(x))>0 else x)
        elif typ=="student_id":
            m[col]=m[col].apply(lambda x: re.sub(r"(^..).*(..$)","\\1****\\2",str(x))
                                if pd.notna(x) else x)
    return m

def analyze_timestamp(series:pd.Series):
    ts=pd.to_datetime(series,errors="coerce").dropna()
    if ts.empty: return None
    return {"hourly":ts.dt.hour.value_counts().sort_index(),
            "daily":ts.dt.date.value_counts().sort_index(),
            "weekday":ts.dt.day_name().value_counts()}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Streamlit ë©”ì¸  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    # ---------- í—¤ë” ----------
    st.markdown('<h1 class="main-header">ğŸ¤– AI ìŠ¤ë§ˆíŠ¸ ì„¤ë¬¸ ë¶„ì„ ì‹œìŠ¤í…œ</h1>', unsafe_allow_html=True)
    st.write("AIê°€ ì»¬ëŸ¼ íƒ€ì…ì„ ì¶”ë¡ í•˜ê³ , ê°ì •Â·í…Œë§ˆÂ·í’ˆì§ˆ ë¶„ì„ ë° ìš”ì•½ ë³´ê³ ì„œë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.")

    # ---------- ì‚¬ì´ë“œë°” ----------
    with st.sidebar:
        st.markdown("### âš™ï¸ ì„¤ì •")
        api_key = st.secrets.get("openai_api_key","")
        if not api_key:
            api_key = st.text_input("OpenAI API Key",type="password")
        if api_key: st.success("API í‚¤ ì„¤ì • ì™„ë£Œ")
        else:       st.warning("AI ê¸°ëŠ¥ ì‚¬ìš©ì„ ìœ„í•´ API í‚¤ ì…ë ¥ í•„ìš”")
        mask_sens  = st.checkbox("ğŸ”’ ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹",True)
        auto_det   = st.checkbox("ğŸ¤– AI ì»¬ëŸ¼ ìë™ ì¶”ë¡ ",True)

    # ---------- CSV ì—…ë¡œë“œ ----------
    file=st.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ",type="csv")
    if not file: return
    df=pd.read_csv(file,encoding="utf-8")
    st.success(f"âœ… {len(df):,}í–‰, {len(df.columns)}ì—´ ë¡œë“œ")

    # ---------- ì»¬ëŸ¼ íƒ€ì… ê°ì§€ ----------
    if auto_det and api_key:
        with st.spinner("GPT-4oë¡œ ì»¬ëŸ¼ íƒ€ì… ì¶”ë¡  ì¤‘â€¦"):
            analyzer=AIAnalyzer(api_key)
            st.session_state.column_configs = analyzer.auto_detect_column_types(df)
        st.info("AIê°€ ì¶”ë¡ í•œ íƒ€ì…ì„ í™•ì¸Â·ìˆ˜ì •í•˜ì„¸ìš”.")
    else:
        st.session_state.column_configs = {c:"other" for c in df.columns}

    # ---------- íƒ€ì… ìˆ˜ë™ ìˆ˜ì • ----------
    col1,col2=st.columns(2)
    for i,c in enumerate(df.columns):
        with (col1 if i%2==0 else col2):
            sel=st.selectbox(f"**{c}**",list(COLUMN_TYPES.keys()),
                index=list(COLUMN_TYPES.keys()).index(st.session_state.column_configs.get(c,"other")),
                format_func=lambda x:COLUMN_TYPES[x],key=f"type_{c}")
            st.session_state.column_configs[c]=sel

    # ---------- ë¶„ì„ ì‹¤í–‰ ----------
    if st.button("ğŸš€ ë¶„ì„ ì‹œì‘",type="primary"):
        analyze_survey(df,st.session_state.column_configs,api_key,mask_sens)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ë¶„ì„ ë©”ì¸ í•¨ìˆ˜  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def analyze_survey(df:pd.DataFrame,
                   configs:Dict[str,str],
                   api_key:str,
                   mask:bool):
    tabs=st.tabs(["ğŸ“Š ê°œìš”","ğŸ“ˆ í†µê³„ ë¶„ì„","ğŸ¤– AI ì¸ì‚¬ì´íŠ¸","ğŸ’¬ í…ìŠ¤íŠ¸ ë¶„ì„","ğŸ“¥ ë³´ê³ ì„œ"])

    # ---------- ê¸°ë³¸ í†µê³„ ----------
    stats={"total_responses":len(df),
           "question_count":len(df.columns),
           "completion_rate":(df.notna().sum().sum()/(len(df)*len(df.columns))*100)}

    with tabs[0]:
        st.markdown('<h2 class="section-header">ğŸ“Š ì „ì²´ ê°œìš”</h2>',unsafe_allow_html=True)
        c1,c2,c3,c4=st.columns(4)
        c1.metric("ì „ì²´ ì‘ë‹µ",f"{stats['total_responses']}ê°œ")
        c2.metric("ì§ˆë¬¸ ìˆ˜",stats['question_count'])
        c3.metric("í‰ê·  ì™„ë£Œìœ¨",f"{stats['completion_rate']:.1f}%")
        null_rate=(df.isna().sum().sum()/(len(df)*len(df.columns))*100)
        c4.metric("ë¯¸ì‘ë‹µë¥ ",f"{null_rate:.1f}%")

        resp_rate=(df.notna().sum()/len(df)*100).sort_values()
        fig=px.bar(x=resp_rate.values,y=resp_rate.index,orientation="h",
                   labels={'x':'ì‘ë‹µë¥ (%)','y':'ì§ˆë¬¸'},color=resp_rate.values,
                   color_continuous_scale='viridis')
        fig.update_layout(height=max(400,len(resp_rate)*25))
        st.plotly_chart(fig,use_container_width=True)

    # ---------- í†µê³„ ë¶„ì„ ----------
    with tabs[1]:
        st.markdown('<h2 class="section-header">ğŸ“ˆ í†µê³„ ë¶„ì„</h2>',unsafe_allow_html=True)
        # íƒ€ì„ìŠ¤íƒ¬í”„
        ts_cols=[c for c,t in configs.items() if t=="timestamp"]
        if ts_cols:
            ts=analyze_timestamp(df[ts_cols[0]])
            if ts:
                st.subheader("â° ì‹œê°„ëŒ€ë³„Â·ì¼ë³„ ë¶„í¬")
                c1,c2=st.columns(2)
                with c1:
                    fig=px.bar(x=ts['hourly'].index,y=ts['hourly'].values,
                               labels={'x':'ì‹œê°„ëŒ€','y':'ì‘ë‹µ'},title="ì‹œê°„ëŒ€ë³„")
                    st.plotly_chart(fig,use_container_width=True)
                with c2:
                    fig=px.line(x=ts['daily'].index,y=ts['daily'].values,
                                markers=True,labels={'x':'ë‚ ì§œ','y':'ì‘ë‹µ'},title="ì¼ë³„ ì¶”ì´")
                    st.plotly_chart(fig,use_container_width=True)
        # ì„ íƒí˜•
        choice_cols=[c for c,t in configs.items() if t in ("single_choice","multiple_choice")]
        for col in choice_cols[:5]:
            st.subheader(col)
            if configs[col]=="multiple_choice":
                vals=[]
                for v in df[col].dropna():
                    vals.extend([x.strip() for x in str(v).split(",")])
                vc=pd.Series(vals).value_counts()
            else:
                vc=df[col].value_counts()
            c1,c2=st.columns(2)
            with c1:
                st.plotly_chart(px.pie(values=vc.values[:10],names=vc.index[:10]),use_container_width=True)
            with c2:
                st.plotly_chart(px.bar(x=vc.values[:10],y=vc.index[:10],orientation="h",
                                       labels={'x':'ì‘ë‹µ','y':'ì„ íƒì§€'}),use_container_width=True)

    # ---------- AI ì¸ì‚¬ì´íŠ¸ ----------
    with tabs[2]:
        st.markdown('<h2 class="section-header">ğŸ¤– AI ì¸ì‚¬ì´íŠ¸</h2>',unsafe_allow_html=True)
        if not api_key:
            st.warning("API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            analyzer=AIAnalyzer(api_key)
            text_cols=[c for c,t in configs.items() if t.startswith("text_")]
            if not text_cols:
                st.info("ë¶„ì„í•  í…ìŠ¤íŠ¸ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                target=st.selectbox("ë¶„ì„í•  í…ìŠ¤íŠ¸ ì»¬ëŸ¼",text_cols)
                if st.button("AI ë¶„ì„ ì‹¤í–‰"):
                    texts=df[target].dropna().astype(str).tolist()
                    with st.spinner("AI ë¶„ì„ ì¤‘â€¦"):
                        sent=analyzer.analyze_text_sentiments(texts,target)
                        theme=analyzer.extract_key_themes(texts,target)
                        qual =analyzer.analyze_response_quality(texts,target)
                    st.session_state.ai_analyses[target]={"sentiment":sent,"themes":theme,"quality":qual}

            # ê²°ê³¼ í‘œì‹œ
            if st.session_state.ai_analyses:
                tar=list(st.session_state.ai_analyses.keys())[-1]
                res=st.session_state.ai_analyses[tar]
                if res.get("sentiment"):
                    st.subheader("ğŸ˜Š ê°ì • ë¶„ì„")
                    st.write(res["sentiment"])
                if res.get("themes"):
                    st.subheader("ğŸ¯ ì£¼ìš” í…Œë§ˆ")
                    st.write(res["themes"])
                if res.get("quality"):
                    st.subheader("ğŸ“Š ì‘ë‹µ í’ˆì§ˆ")
                    st.write(res["quality"])

                if st.button("ğŸ“„ ê²½ì˜ì§„ ìš”ì•½ ìƒì„±"):
                    summary=analyzer.generate_executive_summary(st.session_state.ai_analyses,stats)
                    st.markdown('<div class="ai-insight-box">',unsafe_allow_html=True)
                    st.write(summary)
                    st.markdown('</div>',unsafe_allow_html=True)

    # ---------- í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ ----------
    with tabs[3]:
        st.markdown('<h2 class="section-header">ğŸ’¬ í…ìŠ¤íŠ¸ ë¶„ì„</h2>',unsafe_allow_html=True)
        tcols=[c for c,t in configs.items() if t.startswith("text_")]
        if not tcols:
            st.info("í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for col in tcols:
                st.subheader(col)
                txt=df[col].dropna().astype(str)
                if txt.empty: continue
                lengths=txt.str.len()
                c1,c2,c3,c4=st.columns(4)
                c1.metric("ì‘ë‹µìˆ˜",len(txt))
                c2.metric("í‰ê·  ê¸¸ì´",f"{lengths.mean():.1f}")
                c3.metric("ìµœì†Œ",lengths.min())
                c4.metric("ìµœëŒ€",lengths.max())
                words=re.findall(r'[ê°€-í£]+|[a-zA-Z]+',' '.join(txt).lower())
                words=[w for w in words if w not in STOPWORDS_KO and len(w)>1]
                if words:
                    wc=Counter(words).most_common(15)
                    st.plotly_chart(px.bar(x=[v for _,v in wc],y=[w for w,_ in wc],
                                           orientation="h",labels={'x':'ë¹ˆë„','y':'ë‹¨ì–´'},
                                           color=[v for _,v in wc],
                                           color_continuous_scale='blues'),
                                    use_container_width=True)

    # ---------- ë³´ê³ ì„œ ----------
    with tabs[4]:
        st.markdown('<h2 class="section-header">ğŸ“¥ ë¶„ì„ ë³´ê³ ì„œ</h2>',unsafe_allow_html=True)
        rpt_type=st.selectbox("ë³´ê³ ì„œ ìœ í˜•",["ê¸°ë³¸ í†µê³„","AI ë¶„ì„","ì „ì²´ ì¢…í•©"])
        if st.button("ë³´ê³ ì„œ ìƒì„±"):
            report=generate_report(df,configs,stats,st.session_state.ai_analyses,
                                   rpt_type,mask)
            st.text_area("ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸°",report,height=400)
            st.download_button("TXT ë‹¤ìš´ë¡œë“œ",report.encode("utf-8-sig"),
                               file_name=f"survey_report_{datetime.now():%Y%m%d_%H%M%S}.txt",
                               mime="text/plain")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ë³´ê³ ì„œ ìƒì„±  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_report(df,configs,stats,ai_analyses,rpt_type,mask)->str:
    report=f"""
{'='*60}
ì„¤ë¬¸ ë¶„ì„ ë³´ê³ ì„œ       ìƒì„±:{datetime.now():%Y-%m-%d %H:%M}
{'='*60}

1. ê¸°ë³¸ ì •ë³´
- ì „ì²´ ì‘ë‹µ: {stats['total_responses']}
- ì§ˆë¬¸ ìˆ˜  : {stats['question_count']}
- í‰ê·  ì™„ë£Œìœ¨: {stats['completion_rate']:.1f}%
"""
    # ì»¬ëŸ¼ ìš”ì•½
    report+="\n2. ì»¬ëŸ¼ êµ¬ì„±\n"
    for t,cnt in Counter(configs.values()).most_common():
        report+=f"- {COLUMN_TYPES[t]}: {cnt}ê°œ\n"
    # ìƒì„¸
    report+="\n3. ìƒì„¸ ì»¬ëŸ¼ ì •ë³´\n"
    for col,typ in configs.items():
        resp=(df[col].notna().sum()/len(df))*100
        report+=f"* {col}  [{COLUMN_TYPES[typ]}]  ì‘ë‹µë¥ :{resp:.1f}%\n"
    # AI
    if rpt_type!="ê¸°ë³¸ í†µê³„" and ai_analyses:
        report+="\n4. AI ë¶„ì„ ê²°ê³¼\n"
        for col,res in ai_analyses.items():
            report+=f"\n[{col}]\n"
            if res.get("sentiment"):
                s=res["sentiment"]
                report+=f"- ì „ë°˜ ê°ì •:{s.get('overall_sentiment')}\n"
            if res.get("themes"):
                for th in res['themes'].get('main_themes',[])[:3]:
                    report+=f"- í…Œë§ˆ:{th['theme']} ({th['frequency']*100:.0f}%)\n"
    report+="\n"+"="*60+"\n"
    return report

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ì‹¤í–‰  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    main()
