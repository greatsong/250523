# file: survey_gpt_suite.py  (Streamlit í´ë¼ìš°ë“œ ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸)

import streamlit as st
import pandas as pd
import numpy as np
import koreanize_matplotlib  # ì‚¬ìš©ì í•„ìˆ˜
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
from io import StringIO
import json, re, asyncio, textwrap
from collections import Counter
from openai import OpenAI
from sklearn.cluster import KMeans
from sklearn.metrics import pairwise_distances
from sklearn.preprocessing import normalize
from sklearn.decomposition import PCA
from pptx import Presentation
from pptx.util import Inches, Pt
import pandasql as ps

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
st.set_page_config("GPT ì„¤ë¬¸ ìŠˆíŠ¸", "ğŸ§©", layout="wide")
client = OpenAI(api_key=st.secrets["openai_api_key"])
MODEL_CHAT = "gpt-4o-mini"
MODEL_EMB  = "text-embedding-3-large"

COLUMN_TYPES = {
    "timestamp":"íƒ€ì„ìŠ¤íƒ¬í”„","email":"ì´ë©”ì¼","phone":"ì „í™”ë²ˆí˜¸","name":"ì´ë¦„",
    "numeric":"ìˆ«ì","single_choice":"ë‹¨ì¼ ì„ íƒ","multiple_choice":"ë‹¤ì¤‘ ì„ íƒ",
    "text_short":"ë‹¨ë‹µ í…ìŠ¤íŠ¸","text_long":"ì¥ë¬¸ í…ìŠ¤íŠ¸","other":"ê¸°íƒ€"
}
STOPWORDS = {'ì€','ëŠ”','ì´','ê°€','ì„','ë¥¼','ì˜','ì—','ì™€','ê³¼','ë„','ë¡œ','ìœ¼ë¡œ','ë§Œ',
             'ì—ì„œ','ê¹Œì§€','ë¶€í„°','ë¼ê³ ','í•˜ê³ '}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ GPT ìœ í‹¸ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
@st.cache_data(show_spinner=False)
def gpt_infer_types(sample_csv:str)->dict:
    """GPTâ€‘4oê°€ ì»¬ëŸ¼ ì˜ë¯¸ ì¶”ë¡  â†’ JSON"""
    res = client.chat.completions.create(
        model=MODEL_CHAT,
        messages=[
          {"role":"system","content":
           "You are a data scientist. Infer the semantic data type for each CSV column.\n"
           "Possible types: timestamp, email, phone, name, numeric, single_choice, multiple_choice, "
           "text_short, text_long, other. Return JSON."},
          {"role":"user","content":sample_csv}
        ],
        response_format={"type":"json_object"},
        temperature=0
    )
    return json.loads(res.choices[0].message.content)

def gpt_short_completion(sys,user,format_json=False):
    """ë‹¨ì¼ GPT í˜¸ì¶œ ë˜í¼"""
    res = client.chat.completions.create(
        model=MODEL_CHAT,
        messages=[{"role":"system","content":sys},{"role":"user","content":user}],
        response_format={"type":"json_object"} if format_json else None,
        temperature=0
    )
    return res.choices[0].message.content

async def agpt_many(prompt_tuples):
    """asyncioë¡œ ì—¬ëŸ¬ GPT í˜¸ì¶œ ë³‘ë ¬"""
    loop = asyncio.get_event_loop()
    tasks=[]
    for sys,u in prompt_tuples:
        tasks.append(loop.run_in_executor(
            None, gpt_short_completion, sys, u, False))
    return await asyncio.gather(*tasks)

@st.cache_resource(show_spinner=False)
def embed_texts(texts:list[str])->np.ndarray:
    """OpenAI Embedding (cached)"""
    CHUNK=2048
    vectors=[]
    for i in range(0,len(texts),CHUNK):
        chunk=texts[i:i+CHUNK]
        vecs = client.embeddings.create(model=MODEL_EMB,input=chunk).data
        vectors.extend([v.embedding for v in vecs])
    return np.array(vectors)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CSV ë¡œë“œ & ì „ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def auto_read_csv(uploaded)->pd.DataFrame:
    for enc in ("utf-8","euc-kr","cp949"):
        try:
            return pd.read_csv(StringIO(uploaded.getvalue().decode(enc)))
        except Exception: continue
    raise UnicodeDecodeError("ì¸ì½”ë”© ìë™ íŒë… ì‹¤íŒ¨")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í…ìŠ¤íŠ¸ ë¶„ì„/í† í”½/ê°ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def basic_text_stats(series:pd.Series):
    texts=series.dropna().astype(str)
    if texts.empty: return None
    lens=texts.str.len()
    all_text=' '.join(texts)
    words=re.findall(r'[ê°€-í£]+|[a-zA-Z]+|\d+',all_text.lower())
    words=[w for w in words if w not in STOPWORDS and len(w)>1]
    return {
        "total":len(texts),"avg":lens.mean(),"min":lens.min(),"max":lens.max(),
        "freq":Counter(words).most_common(20)
    }

def topic_clustering(texts:list[int], k:int=5):
    emb=embed_texts(texts)
    k=min(k,len(texts))
    model=KMeans(n_clusters=k,random_state=0,n_init="auto").fit(emb)
    return model.labels_, emb

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ PPT ìë™ ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def make_ppt(overview:str, charts:list[tuple[str,bytes]])->str:
    prs=Presentation()
    slide=prs.slides.add_slide(prs.slide_layouts[1])
    slide.shapes.title.text="AI ì„¤ë¬¸ ë¶„ì„ ìš”ì•½"
    tf=slide.shapes.placeholders[1].text_frame
    for p in textwrap.wrap(overview,60):
        tf.add_paragraph().text=p
    # ì°¨íŠ¸ ì´ë¯¸ì§€ ìŠ¬ë¼ì´ë“œ
    for title,img_bytes in charts:
        s=prs.slides.add_slide(prs.slide_layouts[5])
        s.shapes.title.text=title
        pic=s.shapes.add_picture(img_bytes,Inches(1),Inches(1.5),height=Inches(5))
    fname=f"survey_ai_{datetime.now():%Y%m%d_%H%M%S}.pptx"
    prs.save(fname)
    return fname

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ UI ì‹œì‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
st.title("ğŸ§© GPT ì„¤ë¬¸ ë°ì´í„° ìŠˆíŠ¸")

uploaded=st.file_uploader("CSV ì—…ë¡œë“œ",type="csv")
if not uploaded: st.stop()

df=auto_read_csv(uploaded)
st.success(f"{len(df):,}í–‰ Â· {len(df.columns)}ì—´ ë¡œë“œ ì™„ë£Œ")
with st.expander("ë¯¸ë¦¬ë³´ê¸°"):
    st.dataframe(df.head())

# -------- 1) ì»¬ëŸ¼ íƒ€ì… ìë™ ì¶”ë¡  -------- #
sample=df.head(5).to_csv(index=False)
with st.spinner("GPTê°€ ì»¬ëŸ¼ ì˜ë¯¸ ì¶”ë¡  ì¤‘..."):
    gpt_types=gpt_infer_types(sample)

st.info("ì¶”ë¡  ê²°ê³¼ë¥¼ í™•ì¸/ìˆ˜ì •í•˜ì„¸ìš”")
col_types={}
two_cols=st.columns(2)
for i,c in enumerate(df.columns):
    with two_cols[i%2]:
        sel=st.selectbox(f"**{c}**",list(COLUMN_TYPES.keys()),
            index=list(COLUMN_TYPES.keys()).index(gpt_types.get(c,"other")),
            format_func=lambda x:COLUMN_TYPES[x],key=f"sel_{c}")
        col_types[c]=sel

st.divider()

# í™•ì • í›„ ì¶”ê°€ ê¸°ëŠ¥ ë…¸ì¶œ
if not st.button("ğŸš€ íƒ€ì… í™•ì •",type="primary"): st.stop()

st.session_state["df"]=df
st.session_state["types"]=col_types

# ====== íƒ­ êµ¬ì„± ====== #
tabs=st.tabs([
    "ğŸ“Š ê°œìš” & ì¸ì‚¬ì´íŠ¸","ğŸ”¬ í…ìŠ¤íŠ¸ ë¶„ì„","ğŸ—£ï¸ ìì—°ì–´ Q&A",
    "ğŸ‘¥ í˜ë¥´ì†Œë‚˜","ğŸ¯ ì„¤ë¬¸ ê°œì„  í”¼ë“œë°±","ğŸ“¥ ë‚´ë³´ë‚´ê¸°"
])

# â”€â”€â”€â”€â”€ 2) ê°œìš” & GPT ìš”ì•½ â”€â”€â”€â”€â”€ #
with tabs[0]:
    st.header("ğŸ“Š ì „ì²´ ê°œìš”")
    total,len_q=len(df),len(df.columns)
    completion=(df.notna().sum().sum())/(total*len_q)*100
    st.metric("ì‘ë‹µ ìˆ˜",f"{total:,}")
    st.metric("ì§ˆë¬¸ ìˆ˜",len_q)
    st.metric("í‰ê·  ì‘ë‹µë¥ ",f"{completion:.1f}%")
    # GPT ìš”ì•½ ë²„íŠ¼
    if st.toggle("AI í•œ ì¤„ ìš”ì•½ ìƒì„±(í† í° ì‚¬ìš©)"):
        sys="ë‹¹ì‹ ì€ í†µì°°ë ¥ ìˆëŠ” ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì•„ë˜ í†µê³„ì¹˜ë¥¼ í•œê¸€ë¡œ 2ë¬¸ì¥ ìš”ì•½."
        stats=f"ì‘ë‹µìˆ˜ {total}ê°œ, ì§ˆë¬¸ {len_q}ê°œ, í‰ê·  ì‘ë‹µë¥  {completion:.1f}%"
        with st.spinner("ğŸ“œ ìš”ì•½ ìƒì„± ì¤‘ ..."):
            summary=gpt_short_completion(sys,stats)
        st.success(summary)

# â”€â”€â”€â”€â”€ 3) í…ìŠ¤íŠ¸ ë¶„ì„ â”€â”€â”€â”€â”€ #
with tabs[1]:
    st.header("ğŸ”¬ í…ìŠ¤íŠ¸ ì§ˆë¬¸ ë¶„ì„")
    text_cols=[c for c,t in col_types.items() if t.startswith("text_")]
    if not text_cols:
        st.info("í…ìŠ¤íŠ¸í˜• ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤"); st.stop()
    sel_col=st.selectbox("ë¶„ì„í•  ì»¬ëŸ¼",text_cols)
    stats=basic_text_stats(df[sel_col])
    if not stats: st.warning("ì‘ë‹µ ì—†ìŒ"); st.stop()
    st.write(f"**ì‘ë‹µ ìˆ˜** {stats['total']}  Â·  **í‰ê·  ê¸¸ì´** {stats['avg']:.0f}")
    # í† í”½/ê°ì • ë¶„ì„ í† ê¸€
    run_topic=st.toggle("í† í”½/ê°ì • ë¶„ì„ ì‹¤í–‰(í† í° ì‚¬ìš©)",key="tg_topic")
    if run_topic:
        texts=df[sel_col].dropna().astype(str).tolist()
        labels,emb=topic_clustering(texts,k= st.slider("í´ëŸ¬ìŠ¤í„° ìˆ˜",2,10,5))
        df_topic=pd.DataFrame({"text":texts,"topic":labels})
        st.dataframe(df_topic.head())
        col_counts=df_topic["topic"].value_counts().sort_index()
        fig=px.bar(x=col_counts.index,y=col_counts.values,labels={'x':'í† í”½','y':'ê°œìˆ˜'})
        st.plotly_chart(fig)
        # í† í”½ë³„ ëŒ€í‘œ ë¬¸ì¥ GPT ìš”ì•½
        if st.toggle("í† í”½ë³„ ëŒ€í‘œ í‚¤ì›Œë“œ ìš”ì•½"):
            prompts=[]
            for i in col_counts.index:
                sample=" | ".join(df_topic[df_topic.topic==i]["text"].head(5))
                sys="ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ë¶„ì„ê°€. ì˜ˆì‹œ ë¬¸ì¥ì„ ë³´ê³  í•µì‹¬ í‚¤ì›Œë“œ 3ê°œ í•œê¸€ë¡œ ì½¤ë§ˆë¡œ."
                prompts.append((sys,sample[:4000]))
            with st.spinner("GPT ìš”ì•½ ì¤‘..."):
                summaries=asyncio.run(agpt_many(prompts))
            for i,sm in zip(col_counts.index,summaries):
                st.write(f"**í† í”½ {i}** â†’ {sm}")

# â”€â”€â”€â”€â”€ 4) ìì—°ì–´ Q&A â”€â”€â”€â”€â”€ #
with tabs[2]:
    st.header("ğŸ—£ï¸ ìì—°ì–´ ì§ˆë¬¸ ëŒ€ì‹œë³´ë“œ")
    q=st.chat_input("ì˜ˆ: ë‚¨/ì—¬ ë¹„ìœ¨ì€?")
    if "chat" not in st.session_state: st.session_state.chat=[]
    for role,m in st.session_state.chat:
        st.chat_message(role).write(m)
    if q:
        st.chat_message("user").write(q)
        st.session_state.chat.append(("user",q))
        # GPTì—ê²Œ SQL ìƒì„± ì§€ì‹œ
        cols=list(df.columns)
        sql=gpt_short_completion(
          "SQL expert. DataFrame columns: "+", ".join(cols)+
          ". Return pandasql SELECT for user's question. No explanation.",
          q)
        try:
            res=ps.sqldf(sql,locals())
            st.chat_message("assistant").write(res.head())
            st.session_state.chat.append(("assistant",res.head().to_markdown()))
        except Exception as e:
            st.chat_message("assistant").write(f"âš ï¸ ì˜¤ë¥˜: {e}")
            st.session_state.chat.append(("assistant",str(e)))

# â”€â”€â”€â”€â”€ 5) ì‘ë‹µì í˜ë¥´ì†Œë‚˜ â”€â”€â”€â”€â”€ #
with tabs[3]:
    st.header("ğŸ‘¥ GPT í˜ë¥´ì†Œë‚˜")
    pid_cols=[c for c,t in col_types.items() if t in ("email","phone","name")]
    if not pid_cols:
        st.info("ê°œì¸ ì‹ë³„ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤"); st.stop()
    sel_pid=st.selectbox("ê¸°ì¤€ ì»¬ëŸ¼",pid_cols)
    emails=df[sel_pid].dropna().unique().tolist()[:50]
    if st.button("í˜ë¥´ì†Œë‚˜ ìƒì„± (ìµœëŒ€ 50ëª…, í† í° ì‚¬ìš©)"):
        prompts=[("ë„ˆëŠ” ë§ˆì¼€í„°. ë‹¤ìŒ ì„¤ë¬¸ ì‘ë‹µìœ¼ë¡œ í˜ë¥´ì†Œë‚˜ í•œì¤„ ìš”ì•½.",
                  df[df[sel_pid]==e].iloc[0].to_json()) for e in emails]
        with st.spinner("GPT ìƒì„± ì¤‘"):
            pers=asyncio.run(agpt_many(prompts))
        st.dataframe(pd.DataFrame({"id":emails,"persona":pers}))

# â”€â”€â”€â”€â”€ 6) ì„¤ë¬¸ ê°œì„  í”¼ë“œë°± â”€â”€â”€â”€â”€ #
with tabs[4]:
    st.header("ğŸ¯ ì„¤ë¬¸ ì„¤ê³„ ê°œì„  ì œì•ˆ")
    if st.button("GPT í”¼ë“œë°± ìš”ì²­(í† í° ì‚¬ìš©)"):
        q_text="\n".join([f"{i+1}. {c}" for i,c in enumerate(df.columns)])
        sys="ì „ë¬¸ ë¦¬ì„œì²˜. ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ì™€ ì‘ë‹µë¥  %.1f ë¥¼ ë³´ê³  ê°œì„ ì  5ê°€ì§€."%completion
        fb=gpt_short_completion(sys,q_text)
        st.success(fb)

# â”€â”€â”€â”€â”€ 7) ë‚´ë³´ë‚´ê¸° (PPT í¬í•¨) â”€â”€â”€â”€â”€ #
with tabs[5]:
    st.header("ğŸ“¥ ë°ì´í„°/ë³´ê³ ì„œ/PPT ë‚´ë³´ë‚´ê¸°")
    export=st.selectbox("í˜•ì‹ ì„ íƒ",["ì›ë³¸ CSV","ìµëª… CSV","PPT ë³´ê³ ì„œ"])
    if export=="ì›ë³¸ CSV":
        st.download_button("CSV ë‹¤ìš´ë¡œë“œ",
            df.to_csv(index=False).encode("utf-8-sig"),
            file_name="survey_raw.csv",mime="text/csv")
    elif export=="ìµëª… CSV":
        anon=df.copy()
        for c,t in col_types.items():
            if t=="email": anon[c]=anon[c].str.replace(r'(.{2}).*@','\\1***@',regex=True)
            if t=="name":  anon[c]=anon[c].str.replace(r'(.).+','\\1*',regex=True)
        st.download_button("ìµëª… CSV",
            anon.to_csv(index=False).encode("utf-8-sig"),
            file_name="survey_anon.csv",mime="text/csv")
    else:
        overview=f"ì‘ë‹µ {total}ê°œ, ì§ˆë¬¸ {len_q}ê°œ, ì‘ë‹µë¥  {completion:.1f}%"
        st.info("ì°¨íŠ¸ ì´ë¯¸ì§€ë¥¼ ë„£ìœ¼ë ¤ë©´ ìƒë‹¨ íƒ­ì—ì„œ 'ì¹´ë©”ë¼ ì•„ì´ì½˜ â†’ PNG'ë¡œ ë‹¤ìš´ë°›ì€ í›„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        imgs=st.file_uploader("PNG ì°¨íŠ¸ 3ê°œê¹Œì§€ (ì„ íƒ)",type=["png"],accept_multiple_files=True)
        charts=[]
        for f in imgs[:3]:
            charts.append((f.name,f.name))
            open(f.name,"wb").write(f.read())  # save temp
        fname=make_ppt(overview,charts)
        st.download_button("PPT ë‹¤ìš´ë¡œë“œ",open(fname,"rb").read(),
                           file_name=fname,mime="application/vnd.openxmlformats-officedocument.presentationml.presentation")
