# app.py â”€ Smart Survey Analysis 3.0
# author: Sukree Song âœ¨ with GPT-4o
###############################################################################
#                             ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬                                  #
###############################################################################
import streamlit as st
import pandas as pd
import plotly.express as px
import koreanize_matplotlib
from datetime import datetime
import re, textwrap, tempfile, urllib.request, os, json, asyncio
from collections import Counter
from io import BytesIO
from pathlib import Path
from wordcloud import WordCloud
from openai import OpenAI, AsyncOpenAI
import umap, numpy as np

###############################################################################
#                               FONT HANDLING                                 #
###############################################################################
DEFAULT_FONT = "Nanum Gothic"
CANDIDATES   = [Path("assets/NanumGothic.ttf"), Path("NanumGothic.ttf")]
FONT_PATH    = next((str(p) for p in CANDIDATES if p.exists()), None)
if FONT_PATH is None:               # tmp ë‹¤ìš´ë¡œë“œ
    url = "https://github.com/google/fonts/raw/main/ofl/nanumgothic/NanumGothic-Regular.ttf"
    tmp = Path(tempfile.gettempdir()) / "NanumGothic.ttf"
    if not tmp.exists(): urllib.request.urlretrieve(url, tmp)
    FONT_PATH = str(tmp)

###############################################################################
#                              í˜•íƒœì†Œ ë¶„ì„ ì„¸íŒ…                                #
###############################################################################
try:
    from kiwipiepy import Kiwi
    kiwi = Kiwi()
except ImportError:
    kiwi = None
POS_KEEP  = {"NNG", "NNP", "VV"}
STOPWORDS = {"ê²ƒ","ìˆ˜","ë•Œ","ìƒê°","ì •ë„","ì‚¬ìš©","ì´ë²ˆ","ì´ëŸ°","í•˜ëŠ”","í•˜ë‹¤","ë˜ê³ ","ìˆë‹¤"}

###############################################################################
#                           Streamlit ì „ì—­ ì„¤ì •                                #
###############################################################################
st.set_page_config(
    page_title="ìŠ¤ë§ˆíŠ¸ ì„¤ë¬¸ ë¶„ì„ 3.0",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded",
)
st.markdown(
    f"""
    <style>
    @font-face {{font-family:'{DEFAULT_FONT}'; src:url('https://fonts.gstatic.com/ea/nanumgothic/v5/NanumGothic-Regular.woff2') format('woff2');}}
    html, body, div, svg {{font-family:'{DEFAULT_FONT}', sans-serif !important;}}
    .main-header{{font-size:2.8rem;font-weight:700;background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);-webkit-background-clip:text;-webkit-text-fill-color:transparent;text-align:center;margin:1rem 0 2rem;}}
    .section-header{{font-size:1.8rem;font-weight:600;color:#2d3748;margin:2rem 0 1rem;padding-bottom:.5rem;border-bottom:3px solid #667eea;}}
    .password-box{{max-width:380px;margin:0 auto;padding:2rem;background:#fff;border-radius:15px;box-shadow:0 4px 18px rgba(0,0,0,.08);margin-top:6rem;}}
    </style>
    """,
    unsafe_allow_html=True,
)

###############################################################################
#                        ì„¸ì…˜ ìƒíƒœ ì´ˆê¸° (í† í°Â·í´ë¼ì´ì–¸íŠ¸)                      #
###############################################################################
def get_default_openai_key():
    # ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥ê°’ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ secret, ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ""
    return st.session_state.get("openai_key") or st.secrets.get("openai_api_key", "")

for k, v in {
    "authenticated": False,
    "column_types": {},
    "df": None,
    "token_used": 0,
    "openai_key": "",  # ì‚¬ìš©ì ì…ë ¥ ìš°ì„ , ì—†ìœ¼ë©´ secretì—ì„œ get_default_openai_keyë¡œ ë³´ì¶©
}.items():
    st.session_state.setdefault(k, v)

def get_client(async_mode=False):
    key = get_default_openai_key()
    if not key: return None
    return (AsyncOpenAI if async_mode else OpenAI)(api_key=key)

###############################################################################
#                               ë¹„ë°€ë²ˆí˜¸ ì²´í¬                                  #
###############################################################################
CORRECT_PASSWORD = "zzolab"
def check_password() -> bool:
    if st.session_state.authenticated: return True
    st.markdown('<div class="password-box">', unsafe_allow_html=True)
    pwd = st.text_input("ğŸ” ë¹„ë°€ë²ˆí˜¸", type="password")
    if st.button("í™•ì¸", use_container_width=True):
        if pwd == CORRECT_PASSWORD:
            st.session_state.authenticated = True
            st.rerun()
        else:
            st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    st.markdown("</div>", unsafe_allow_html=True)
    return False

###############################################################################
#                              GPT ìœ í‹¸ë¦¬í‹°                                   #
###############################################################################
@st.cache_data(show_spinner=False)
def gpt_guess_types(cols:list[str]):
    client = get_client()
    if client is None: return {}
    prompt = "\n".join(f"- {c}" for c in cols)
    sysmsg = (
    "ì•„ë˜ëŠ” ì„¤ë¬¸ ë°ì´í„°ì˜ ì»¬ëŸ¼ëª…(ë¬¸í•­ëª…) ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. "
    "ê° ë¬¸í•­ì´ ì–´ë–¤ ë°ì´í„° íƒ€ì…ì— í•´ë‹¹í•˜ëŠ”ì§€ ê°€ì¥ ì í•©í•œ í•œ ê°€ì§€ë¥¼ ì„ íƒí•´ ì»¬ëŸ¼ëª…:íƒ€ì… ìŒì˜ JSON ì˜¤ë¸Œì íŠ¸ë¡œ ë‹µí•˜ì„¸ìš”.\n\n"
    "ì„ íƒ ê°€ëŠ¥í•œ íƒ€ì…:\n"
    "- timestamp: ë‚ ì§œ, ì‹œê°„ ë“±(ì˜ˆ: 'ì‘ë‹µ ì‹œê°„', 'ì œì¶œì¼', 'Date')\n"
    "- text_short: ì§§ì€ ì£¼ê´€ì‹(ì˜ˆ: 'ì§ì—…', 'í•œ ì¤„ ì†Œê°œ', 'ì„±ë³„', 'ê±°ì£¼ì§€')\n"
    "- text_long: ê¸´ ì£¼ê´€ì‹(ì˜ˆ: 'ê¸°ì–µì— ë‚¨ëŠ” ê²½í—˜', 'ì˜ê²¬ì„ ììœ ë¡­ê²Œ ì‘ì„±', 'ê±´ì˜ì‚¬í•­')\n"
    "- single_choice: ê°ê´€ì‹ ë‹¨ì¼ì„ íƒ(ì˜ˆ: 'ì„±ë³„', 'í•™ë…„', 'ì„ í˜¸ë„', 'Yes/No', 'ì§€ì—­ ì„ íƒ')\n"
    "- multiple_choice: ê°ê´€ì‹ ë‹¤ì¤‘ì„ íƒ(ì˜ˆ: 'ê´€ì‹¬ ë¶„ì•¼(ì¤‘ë³µ ì„ íƒ)', 'í¬ë§ ê³¼ëª©(ë³µìˆ˜ ì‘ë‹µ ê°€ëŠ¥)')\n"
    "- numeric: ìˆ«ì/ìˆ˜ì¹˜(ì˜ˆ: 'ë‚˜ì´', 'ì ìˆ˜', 'ì—°ë ¹')\n"
    "- email: ì´ë©”ì¼ ì£¼ì†Œ(ì˜ˆ: 'ì´ë©”ì¼', 'email')\n"
    "- phone: ì „í™”ë²ˆí˜¸(ì˜ˆ: 'íœ´ëŒ€í° ë²ˆí˜¸', 'ì—°ë½ì²˜')\n"
    "- name: ì´ë¦„(ì˜ˆ: 'ì„±ëª…', 'ì´ë¦„')\n"
    "- student_id: í•™ë²ˆ/ì‚¬ë²ˆ ë“±(ì˜ˆ: 'í•™ë²ˆ', 'ID')\n"
    "- other: ìœ„ì˜ ì–´ëŠ ê²ƒë„ ì•„ë‹Œ ê²½ìš°\n\n"
    "ì•„ë˜ ì˜ˆì‹œë¥¼ ì°¸ê³ í•˜ì„¸ìš”:\n"
    "ì˜ˆì‹œ ì…ë ¥:\n- ì´ë¦„\n- ì„±ë³„\n- í¬ë§ê³¼ëª©(ë³µìˆ˜ì‘ë‹µ)\n- ììœ ì˜ê²¬\n- ì œì¶œì¼\n- íœ´ëŒ€í° ë²ˆí˜¸\n"
    "ì˜ˆì‹œ ë‹µë³€:\n"
    "{\"ì´ë¦„\":\"name\", \"ì„±ë³„\":\"single_choice\", \"í¬ë§ê³¼ëª©(ë³µìˆ˜ì‘ë‹µ)\":\"multiple_choice\", \"ììœ ì˜ê²¬\":\"text_long\", \"ì œì¶œì¼\":\"timestamp\", \"íœ´ëŒ€í° ë²ˆí˜¸\":\"phone\"}\n\n"
    "ì•„ë˜ ì»¬ëŸ¼ë“¤ì„ ë¶„ì„í•´ ë™ì¼í•œ ë°©ì‹ì˜ JSONìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”. "
    )

    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role":"system","content":sysmsg},
                  {"role":"user","content":prompt}],
        temperature=0.1,
        max_tokens=300,
    )
    try:
        return json.loads(res.choices[0].message.content)
    except Exception:
        return {}

def stream_longtext_summary(texts:str):
    client = get_client()
    if client is None: return
    sys = "ë„ˆëŠ” ë›°ì–´ë‚œ í•œêµ­ì–´ ë°ì´í„° ë¶„ì„ê°€ë‹¤. ì£¼ìš” ì£¼ì œ 3-5ê°œì™€ ê° ì£¼ì œ ëŒ€í‘œë¬¸ì¥ì„ ì¶œë ¥í•´ë¼."
    with st.spinner("ğŸ§  GPT ìš”ì•½ ì¤‘â€¦"):
        for chunk in client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role":"system","content":sys},
                      {"role":"user","content":texts}],
            stream=True,
            temperature=0.3,
            max_tokens=500,
        ):
            delta = chunk.choices[0].delta.content
            if delta: st.write(delta, unsafe_allow_html=True)

def count_tokens(resp):
    st.session_state.token_used += resp.usage.total_tokens if hasattr(resp,"usage") else 0

###############################################################################
#                            ê¸°ë³¸ ë¶„ì„ í•¨ìˆ˜                                    #
###############################################################################
def tokenize_ko(text:str):
    if kiwi:
        return [t.lemma if t.tag.startswith("V") else t.form
                for t in kiwi.tokenize(text, normalize_coda=True)
                if t.tag in POS_KEEP]
    return re.findall(r"[ê°€-í£]{2,}", text)

def analyze_text(col:pd.Series):
    texts = col.dropna().astype(str)
    if texts.empty: return None
    tokens = [w for s in texts for w in tokenize_ko(s) if w not in STOPWORDS]
    freq  = Counter(tokens)
    stats = {"total":len(texts),
             "avg":texts.str.len().mean(),
             "min":texts.str.len().min(),
             "max":texts.str.len().max()}
    return {"freq":freq, "stats":stats}

def create_wordcloud(freq):
    if not freq: return None
    wc  = WordCloud(font_path=FONT_PATH, width=800,height=400,background_color="white")
    img = wc.generate_from_frequencies(freq)
    buf = BytesIO(); img.to_image().save(buf,"PNG")
    return buf.getvalue()

###############################################################################
#                           Embedding & Cluster                               #
###############################################################################
@st.cache_data(show_spinner=False)
def embed_texts(texts:list[str]):
    client = get_client()
    if client is None: return np.zeros((len(texts), 384))
    embs = client.embeddings.create(model="text-embedding-3-small", input=texts).data
    vec  = np.array([e.embedding for e in embs])
    return vec

def plot_clusters(vecs:np.ndarray, texts:list[str]):
    reducer = umap.UMAP(random_state=42)
    coords  = reducer.fit_transform(vecs)
    fig = px.scatter(x=coords[:,0], y=coords[:,1], hover_data=[texts],
                     title="í…ìŠ¤íŠ¸ ì‘ë‹µ ì„ë² ë”© í´ëŸ¬ìŠ¤í„°")
    st.plotly_chart(fig, use_container_width=True)

###############################################################################
#                            PII ë§ˆìŠ¤í‚¹ (ê·œì¹™ + GPT)                           #
###############################################################################
def regex_mask(pattern, repl, s):
    return re.sub(pattern, repl, s) if pd.notna(s) else s

def gpt_mask(texts:list[str]):
    client = get_client()
    if client is None: return texts
    sys = ("ë‹¤ìŒ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ì—ì„œ ê°œì¸ì •ë³´(ì´ë¦„Â·ì „í™”Â·ì´ë©”ì¼Â·í•™ë²ˆ ë“±)ë¥¼ ë°œê²¬í•˜ë©´ "
           "ê° ì›ì†Œë¥¼ *** ë¡œ ë§ˆìŠ¤í‚¹í•˜ê³ , ê°œì¸ì •ë³´ê°€ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë‘ì–´ë¼. "
           "JSON ë¦¬ìŠ¤íŠ¸ë¡œë§Œ ê²°ê³¼ë¥¼ ì¶œë ¥í•´ë¼.")
    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role":"system","content":sys},
                  {"role":"user","content":json.dumps(texts, ensure_ascii=False)}],
        temperature=0,
        max_tokens=500,
    )
    return json.loads(res.choices[0].message.content)

###############################################################################
#                               ë³´ê³ ì„œ GPT ìƒì„±                                #
###############################################################################
def gpt_make_report(meta:str, style:str):
    client = get_client()
    if client is None: return ""
    prompt = f"""
    ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ë³´ê³ ì„œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì›í•˜ëŠ” ìŠ¤íƒ€ì¼: {style}
    ë‹¤ìŒ ë©”íƒ€ë°ì´í„°ë¥¼ ë³´ê³  ì•Œì°¨ê³  ê°„ê²°í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    ---
    {meta}
    """
    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role":"user","content":prompt}],
        temperature=0.3,
        max_tokens=600,
    )
    return res.choices[0].message.content.strip()

###############################################################################
#                               ì±—ë´‡ (ë°ì´í„° Q&A)                             #
###############################################################################
QA_SYS = "ë„ˆëŠ” ë°ì´í„° ë¶„ì„ ë³´ì¡° AIë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ í•œêµ­ì–´ë¡œ ì´í•´í•˜ê³  DataFrameì— ê¸°ë°˜í•œ ëŒ€ë‹µì„ í•´ë¼."

def chat_with_df(df:pd.DataFrame, query:str):
    client = get_client()
    if client is None: return "API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    sample = df.head(50).to_json(orient="split", force_ascii=False)
    prompt = f"DataFrame ìƒ˜í”Œ:```json\n{sample}\n```\nì§ˆë¬¸: {query}"
    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role":"system","content":QA_SYS},
                  {"role":"user","content":prompt}],
        temperature=0.2, max_tokens=400)
    return res.choices[0].message.content.strip()

###############################################################################
#                                MAIN                                          #
###############################################################################
def main():
    if not check_password(): return

    st.sidebar.header("ğŸ”‘ OpenAI API Key")
    st.sidebar.text_input("sk-...", type="password",
                          key="openai_key",
                          placeholder="í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ì—¬ê¸° ì…ë ¥")
    openai_key = get_default_openai_key()
    if not openai_key:
        st.sidebar.warning("API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”! (ì¼ë¶€ ê¸°ëŠ¥ ì œí•œ)")
    st.sidebar.markdown(f"**í† í° ì‚¬ìš©ëŸ‰**: {st.session_state.token_used:,}")

    st.markdown('<h1 class="main-header">ğŸ“Š ìŠ¤ë§ˆíŠ¸ ì„¤ë¬¸ ë¶„ì„ ì‹œìŠ¤í…œ 3.0</h1>',
                unsafe_allow_html=True)

    uploaded = st.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])
    if uploaded is None: return
    try:
        df = pd.read_csv(uploaded, encoding="utf-8")
    except Exception as e:
        st.error(f"CSV ì½ê¸° ì˜¤ë¥˜: {e}"); return
    st.session_state.df = df

    # â”€â”€ GPT ì»¬ëŸ¼ íƒ€ì… ì œì•ˆ
    col_types = {}
    type_list = ["timestamp","text_short","text_long","single_choice",
                 "multiple_choice","numeric","email","phone","name",
                 "student_id","other"]
    if openai_key:
        with st.spinner("ğŸ§  GPTê°€ ì»¬ëŸ¼ íƒ€ì… ì¶”ì • ì¤‘..."):
            col_types = gpt_guess_types(df.columns.tolist())

    left,right = st.columns(2)
    for i,col in enumerate(df.columns):
        target = left if i%2==0 else right
        guess  = col_types.get(col,"other")
        with target:
            st.session_state.column_types[col] = st.selectbox(
                label=col, options=type_list,
                index=type_list.index(guess) if guess in type_list else len(type_list)-1,
                key=f"tt_{col}"
            )

    st.divider()
    if not st.button("ğŸš€ ë¶„ì„ ì‹œì‘", use_container_width=True): return
    cfg = st.session_state.column_types

    # â”€â”€ í…ìŠ¤íŠ¸ ë¶„ì„
    txt_results = {c: analyze_text(df[c]) for c,t in cfg.items() if t in {"text_short","text_long"}}

    tab_over, tab_text, tab_cluster, tab_chat, tab_export = st.tabs(
        ["ğŸ“Š ê°œìš”","ğŸ” í…ìŠ¤íŠ¸","ğŸ–¼ï¸ í´ëŸ¬ìŠ¤í„°","ğŸ’¬ ì±—ë´‡","ğŸ“¥ ë‚´ë³´ë‚´ê¸°"])

    # â–¸ Overview
    with tab_over:
        st.markdown('<h2 class="section-header">ğŸ“Š ê°œìš”</h2>', unsafe_allow_html=True)
        c1,c2,c3 = st.columns(3)
        c1.metric("ì‘ë‹µ ìˆ˜",f"{len(df):,}")
        c2.metric("ì§ˆë¬¸ ìˆ˜",len(df.columns))
        comp = df.notna().sum().sum() / (len(df)*len(df.columns))*100
        c3.metric("í‰ê·  ì‘ë‹µë¥ ",f"{comp:.1f}%")

        resp_rate = (df.notna().sum()/len(df)*100).sort_values()
        fig = px.bar(x=resp_rate.values,y=resp_rate.index,orientation="h",
                     labels={"x":"ì‘ë‹µë¥ (%)","y":"ì§ˆë¬¸"},
                     color=resp_rate.values,color_continuous_scale="viridis")
        fig.update_layout(height=max(400,len(resp_rate)*30),showlegend=False)
        st.plotly_chart(fig, use_container_width=True)

    # â–¸ Text
    with tab_text:
        st.markdown('<h2 class="section-header">ğŸ” í…ìŠ¤íŠ¸ ë¶„ì„</h2>', unsafe_allow_html=True)
        if not txt_results: st.info("í…ìŠ¤íŠ¸ í˜•ì‹ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        for col,res in txt_results.items():
            if not res: continue
            st.subheader(f"ğŸ“ {col}")
            s = res["stats"]
            c1,c2,c3,c4 = st.columns(4)
            c1.metric("ì‘ë‹µ",s["total"])
            c2.metric("í‰ê·  ê¸¸ì´",f"{s['avg']:.0f}ì")
            c3.metric("ìµœì†Œ",f"{s['min']}ì")
            c4.metric("ìµœëŒ€",f"{s['max']}ì")
            wc_image = create_wordcloud(res["freq"])
            if wc_image: st.image(wc_image,use_column_width=True)

            if cfg[col]=="text_long" and openai_key:
                with st.expander("ğŸ’¡ GPT ì£¼ìš” ì£¼ì œ/ë¬¸ì¥"):
                    top_n = 100
                    sample = df[col].dropna().astype(str).sort_values(key=lambda s:s.str.len(),ascending=False).head(top_n)
                    joined = "\n\n".join(sample.tolist())[:12000]
                    stream_longtext_summary(joined)

    # â–¸ Cluster
    with tab_cluster:
        st.markdown('<h2 class="section-header">ğŸ–¼ï¸ ì„ë² ë”© í´ëŸ¬ìŠ¤í„°</h2>', unsafe_allow_html=True)
        long_cols = [c for c,t in cfg.items() if t=="text_long"]
        if not long_cols:
            st.info("text_long ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤."); 
        elif not openai_key:
            st.warning("API í‚¤ í•„ìš”");
        else:
            col_pick = st.selectbox("ì„ë² ë”© ëŒ€ìƒ ì»¬ëŸ¼", long_cols)
            texts = df[col_pick].dropna().astype(str).tolist()
            vecs  = embed_texts(texts)
            plot_clusters(vecs, texts)

    # â–¸ Chatbot
    with tab_chat:
        st.markdown('<h2 class="section-header">ğŸ’¬ ë°ì´í„° ì±—ë´‡</h2>', unsafe_allow_html=True)
        if not openai_key:
            st.warning("API í‚¤ í•„ìš”")
        else:
            query = st.text_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•œê°€ìš”? (ì˜ˆ: 'ì‘ë‹µìì˜ í‰ê·  ì—°ë ¹ì€?')")
            if st.button("ë‹µë³€ ìš”ì²­") and query:
                answer = chat_with_df(df, query)
                st.info(answer)

    # â–¸ Export
    with tab_export:
        st.markdown('<h2 class="section-header">ğŸ“¥ ë°ì´í„° ë‚´ë³´ë‚´ê¸°</h2>', unsafe_allow_html=True)
        fmt = st.radio("í˜•ì‹ ì„ íƒ",["CSV ì›ë³¸","GPT ë³´ê³ ì„œ","ìµëª… CSV"])
        if fmt=="CSV ì›ë³¸":
            csv = df.to_csv(index=False,encoding="utf-8-sig")
            st.download_button("ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",csv,file_name=f"survey_{datetime.now():%Y%m%d_%H%M%S}.csv",mime="text/csv")
        elif fmt=="GPT ë³´ê³ ì„œ":
            style = st.selectbox("ë³´ê³ ì„œ ìŠ¤íƒ€ì¼",["ìš”ì•½TXT","ê²½ì˜ì ë©”ì¼","êµì‚¬ìš© ë¸Œë¦¬í”„"])
            meta  = {
                "rows":len(df),"cols":len(df.columns),
                "text_keywords":{c:[(w,cnt) for w,cnt in res["freq"].most_common(10)]
                                 for c,res in txt_results.items()}
            }
            if st.button("ğŸ“ GPT ë³´ê³ ì„œ ìƒì„±"):
                report = gpt_make_report(json.dumps(meta,ensure_ascii=False), style)
                st.download_button("ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",report,file_name=f"survey_report_{datetime.now():%Y%m%d_%H%M%S}.txt",mime="text/plain")
        else:                                  # ìµëª…
            anon = df.copy()
            if openai_key:                         # GPT ë§ˆìŠ¤í‚¹ (ê°„ë‹¨ ìƒ˜í”Œ)
                for col,t in cfg.items():
                    if t in {"name","email","phone","student_id"}:
                        batch = anon[col].fillna("").astype(str).tolist()
                        masked = gpt_mask(batch)
                        anon[col] = masked
            csv = anon.to_csv(index=False,encoding="utf-8-sig")
            st.download_button("ğŸ“¥ ìµëª… CSV ë‹¤ìš´ë¡œë“œ",csv,file_name=f"survey_anon_{datetime.now():%Y%m%d_%H%M%S}.csv",mime="text/csv")

###############################################################################
#                               Run                                            #
###############################################################################
if __name__ == "__main__":
    main()
