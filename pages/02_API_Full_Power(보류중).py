"""
survey_dashboard.py â€¯(Final patched)
-------------------------------------------------
- requirements: streamlit, pandas, numpy, plotly, koreanize_matplotlib, kiwipiepy, wordcloud, openai, umap-learn
- ëª¨ë“  ì•Œë ¤ì§„ ì˜¤ë¥˜(umap ë¯¸ì„¤ì¹˜, WordCloud í°íŠ¸, GPT ëª¨ë¸ fallback, duplicate key, empty data ê°€ë“œ, cache í•´ì‹±) í•´ê²°
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import koreanize_matplotlib  # í•œê¸€ ì¶•
import re, json, textwrap, io, base64, os, tempfile, urllib.request, time
from datetime import datetime
from collections import Counter
from typing import Dict, List
from openai import OpenAI
from wordcloud import WordCloud
import matplotlib.pyplot as plt

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ì˜ì¡´ íŒ¨í‚¤ì§€ ì²´í¬ (umap)  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    import umap.umap_ as umap
except ModuleNotFoundError:
    umap = None  # í´ëŸ¬ìŠ¤í„° íƒ­ì—ì„œ ì•ˆë‚´ ë©”ì‹œì§€ ì¶œë ¥

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Streamlit ì„¤ì •  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config("AI ì„¤ë¬¸ ëŒ€ì‹œë³´ë“œ", "ğŸ¤–", layout="wide")
CSS = """
<style>
.main-header{font-size:2.5rem;font-weight:700;text-align:center;background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);-webkit-background-clip:text;-webkit-text-fill-color:transparent;margin:1rem 0;}
.section-header{font-size:1.6rem;font-weight:600;border-bottom:3px solid #667eea;margin:1.3rem 0 .8rem 0;}
</style>
"""
st.markdown(CSS, unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ìƒìˆ˜  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
COLUMN_TYPES = {
    "timestamp":"íƒ€ì„ìŠ¤íƒ¬í”„","email":"ì´ë©”ì¼","phone":"ì „í™”ë²ˆí˜¸","name":"ì´ë¦„","student_id":"í•™ë²ˆ/ì‚¬ë²ˆ","numeric":"ìˆ«ì","single_choice":"ë‹¨ì¼ ì„ íƒ","multiple_choice":"ë‹¤ì¤‘ ì„ íƒ","linear_scale":"ì²™ë„","text_short":"ì§§ì€ í…ìŠ¤íŠ¸","text_long":"ê¸´ í…ìŠ¤íŠ¸","url":"URL","other":"ê¸°íƒ€"}
STOP_KO={'ì€','ëŠ”','ì´','ê°€','ì„','ë¥¼','ì˜','ì—','ì™€','ê³¼','ë„','ë¡œ','ìœ¼ë¡œ','ë§Œ','ì—ì„œ','ê¹Œì§€','ë¶€í„°','ë¼ê³ ','í•˜ê³ ','ìˆë‹¤','ìˆëŠ”','ìˆê³ ','í•©ë‹ˆë‹¤','ì…ë‹ˆë‹¤','ëœë‹¤'}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  í°íŠ¸ íƒìƒ‰  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FONT_CANDIDATES=[
    "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
    "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
    "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf"
]

def get_font_path():
    for p in FONT_CANDIDATES:
        if os.path.exists(p):
            return p
    # ë‹¤ìš´ë¡œë“œ ì‹œë„ (Nanum)
    url="https://github.com/google/fonts/raw/main/ofl/nanumgothic/NanumGothic-Regular.ttf"
    tmp=Path(tempfile.gettempdir())/"NanumGothic.ttf"
    if not tmp.exists():
        try: urllib.request.urlretrieve(url,tmp)
        except Exception: return None
    return str(tmp)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ì„¸ì…˜ ì´ˆê¸°í™”  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for k,v in [("df",None),("configs",{}),("ai",{}),("ai_done",False)]:
    if k not in st.session_state: st.session_state[k]=v

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  OpenAI Helper  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_openai_key():
    return st.session_state.get("openai_key") or st.secrets.get("openai_api_key","")

def get_client():
    key=get_openai_key()
    return OpenAI(api_key=key) if key else None

# GPT ëª¨ë¸ í˜¸ì¶œ wrapper (fallback)

def chat_completion_safe(messages:list, temperature=0, max_tokens=512, model="gpt-4o"):
    client=get_client()
    if client is None:
        return None
    try:
        return client.chat.completions.create(model=model,messages=messages,temperature=temperature,max_tokens=max_tokens)
    except Exception:
        return client.chat.completions.create(model="gpt-4o",messages=messages,temperature=temperature,max_tokens=max_tokens)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ì»¬ëŸ¼ íƒ€ì… ì¶”ë¡   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner=False, hash_funcs={pd.DataFrame: lambda _: None})
def gpt_guess_types(df_csv:str, cols:list[str]):
    client=get_client()
    if client is None:
        return {}
    sys="ì•„ë˜ CSV ìƒ˜í”Œì˜ ê° ì»¬ëŸ¼ íƒ€ì…ì„ JSONìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”. íƒ€ì…: "+", ".join(COLUMN_TYPES)
    user=df_csv
    res=chat_completion_safe([{"role":"system","content":sys},{"role":"user","content":user}],max_tokens=800)
    try:
        return json.loads(res.choices[0].message.content)
    except Exception:
        return {}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  WordCloud  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def gen_wordcloud(freq:dict):
    if not freq or len(freq)<2:
        return None
    wc=WordCloud(width=800,height=400,background_color="white",font_path=get_font_path() or None)
    img=wc.generate_from_frequencies(freq)
    buf=io.BytesIO()
    img.to_image().save(buf,format="PNG")
    return buf.getvalue()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ì„ë² ë”©  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner=False)
def embed_texts(texts:list[str]):
    client=get_client()
    if client is None or len(texts)==0:
        return np.zeros((0,384))
    texts=[t[:512] for t in texts[:500]]  # ê¸¸ì´Â·ê°œìˆ˜ ì œí•œ
    embs=client.embeddings.create(model="text-embedding-3-small",input=texts).data
    vec=np.array([e.embedding for e in embs])
    return vec

def plot_clusters(vec:np.ndarray,texts:list[str]):
    if umap is None:
        st.warning("umapâ€‘learn ë¯¸ì„¤ì¹˜ë¡œ í´ëŸ¬ìŠ¤í„° ê¸°ëŠ¥ ì‚¬ìš© ë¶ˆê°€")
        return
    if vec.size==0:
        st.info("ì„ë² ë”© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    coords=umap.UMAP(random_state=42).fit_transform(vec)
    fig=px.scatter(x=coords[:,0],y=coords[:,1],hover_data=[texts],title="í…ìŠ¤íŠ¸ ì„ë² ë”© í´ëŸ¬ìŠ¤í„°")
    st.plotly_chart(fig,use_container_width=True,key=f"cluster_{time.time()}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ë¶„ì„ í•¨ìˆ˜  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def tokenize_ko(text:str):
    return re.findall(r"[ê°€-í£]{2,}",text)

def analyze_text(col:pd.Series):
    texts=col.dropna().astype(str)
    if texts.empty:
        return None
    tokens=[w for s in texts for w in tokenize_ko(s) if w not in STOP_KO]
    freq=Counter(tokens)
    lens=texts.str.len()
    stats={"total":len(texts),"avg":lens.mean(),"min":lens.min(),"max":lens.max()}
    return {"freq":freq,"stats":stats}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  MAIN  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    st.markdown('<div class="main-header">ğŸ“Š AI ìŠ¤ë§ˆíŠ¸ ì„¤ë¬¸ ëŒ€ì‹œë³´ë“œ</div>',unsafe_allow_html=True)

    # -- Sidebar
    with st.sidebar:
        st.text_input("OpenAI API Key",type="password",key="openai_key",placeholder="sk-...")
        auto_type=st.checkbox("ğŸ¤– ì»¬ëŸ¼ ìë™ ì¶”ë¡ ",True)

    file=st.file_uploader("CSV ì—…ë¡œë“œ",type="csv")
    if not file:
        return
    df=pd.read_csv(file)

    # â”€â”€ ì»¬ëŸ¼ íƒ€ì… ìë™ ì¶”ë¡ 
    if auto_type and not st.session_state.configs and get_openai_key():
        with st.spinner("GPT ì»¬ëŸ¼ ì¶”ë¡  ì¤‘..."):
            st.session_state.configs=gpt_guess_types(df.head(3).to_csv(index=False),list(df.columns)) or {}
    if not st.session_state.configs:
        st.session_state.configs={c:"other" for c in df.columns}
    configs=st.session_state.configs

    # â”€â”€ íƒ€ì… ìˆ˜ì • UI
    with st.expander("ì»¬ëŸ¼ íƒ€ì… í™•ì¸/ìˆ˜ì •",False):
        c1,c2=st.columns(2)
        for idx,col in enumerate(df.columns):
            with (c1 if idx%2==0 else c2):
                configs[col]=st.selectbox(col,list(COLUMN_TYPES.keys()),index=list(COLUMN_TYPES.keys()).index(configs[col]),key=f"sel_{col}")

    page=st.radio("ë©”ë‰´",["ğŸ“Š ê°œìš”","ğŸ“ˆ í†µê³„","ğŸ“ ìˆ«ì/ì²™ë„","ğŸ¤– í…ìŠ¤íŠ¸"],horizontal=True,key="nav")

    # ---- Overview
    if page=="ğŸ“Š ê°œìš”":
        st.markdown('<h2 class="section-header">ğŸ“Š ê°œìš”</h2>',unsafe_allow_html=True)
        tot,qs=len(df),len(df.columns)
        st.metric("ì‘ë‹µ",tot)
        st.metric("ì§ˆë¬¸",qs)
        comp=df.notna().sum().sum()/(tot*qs)*100
        st.metric("í‰ê·  ì™„ë£Œìœ¨",f"{comp:.1f}%")
        rate=(df.notna().sum()/tot*100).sort_values()
        st.plotly_chart(px.bar(x=rate.values,y=rate.index,orientation="h",labels={'x':'ì‘ë‹µë¥ ','y':'ì§ˆë¬¸'},color=rate.values,color_continuous_scale='viridis'),use_container_width=True,key="bar_overview")

    # ---- í†µê³„
    elif page=="ğŸ“ˆ í†µê³„":
        st.markdown('<h2 class="section-header">ğŸ“ˆ ì„ íƒí˜•Â·ì‹œê°„ ë¶„ì„</h2>',unsafe_allow_html=True)
        ts_cols=[c for c,t in configs.items() if t=="timestamp"]
        if ts_cols:
            ts=ts_info(df[ts_cols[0]])
            if ts:
                heat_df=ts['heat'].reset_index(); heat_df['date']=heat_df['index'].dt.date.astype(str); heat_df['hour']=heat_df['index'].dt.hour
                st.plotly_chart(px.density_heatmap(heat_df,x='hour',y='date',z='index',histfunc='count',color_continuous_scale='Blues'),use_container_width=True,key="heat_ts")
        choice=[c for c,t in configs.items() if t in ("single_choice","multiple_choice")]
        for i,col in enumerate(choice[:5]):
            if configs[col]=="multiple_choice":
                vals=[x.strip() for v in df[col].dropna().astype(str) for x in v.split(',')]
            else:
                vals=df[col].dropna().astype(str).tolist()
            vc=pd.Series(vals).value_counts()
            st.plotly_chart(px.treemap(names=vc.index[:15],parents=[""]*15,values=vc.values[:15]),use_container_width=True,key=f"tree_{col}")

    # ---- ìˆ«ì/ì²™ë„
    elif page=="ğŸ“ ìˆ«ì/ì²™ë„":
        st.markdown('<h2 class="section-header">ğŸ“ ìˆ«ì/ì²™ë„ ë¶„ì„</h2>',unsafe_allow_html=True)
        num=[c for c,t in configs.items() if t in ("numeric","linear_scale")]
        if not num:
            st.info("ìˆ«ì/ì²™ë„ ì»¬ëŸ¼ ì—†ìŒ")
        for col in num:
            data=pd.to_numeric(df[col],errors='coerce').dropna()
            if data.empty:
                continue
            c1,c2=st.columns(2)
            with c1:
                st.plotly_chart(px.histogram(data,nbins=20,title=col),use_container_width=True,key=f"hist_{col}")
            with c2:
                st.plotly_chart(px.box(y=data,points="all",title=col),use_container_width=True,key=f"box_{col}")

    # ---- í…ìŠ¤íŠ¸
    else:
        st.markdown('<h2 class="section-header">ğŸ¤– í…ìŠ¤íŠ¸ ì¸ì‚¬ì´íŠ¸</h2>',unsafe_allow_html=True)
        txt_cols=[c for c,t in configs.items() if t.startswith("text_")]
        if not txt_cols:
            st.info("í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì—†ìŒ")
            return
        sel=st.selectbox("ë¶„ì„ ëŒ€ìƒ",txt_cols,key="txtsel")
        res=analyze_text(df[sel])
        if res:
            wc=gen_wordcloud(res['freq'])
            if wc:
                st.image(wc,caption="WordCloud")
            else:
                st.info("ë‹¨ì–´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ WordCloud ìƒëµ")
            if get_openai_key():
                with st.expander("GPT ìš”ì•½"):
                    summary=AIAnalyzer(get_openai_key()).summarize(df[sel].dropna().astype(str).tolist(),sel)
                    st.write(summary)
            # í´ëŸ¬ìŠ¤í„°
            if st.checkbox("ì„ë² ë”© í´ëŸ¬ìŠ¤í„° ë³´ê¸°"):
                vec=embed_texts(df[sel].dropna().astype(str).tolist())
                plot_clusters(vec,df[sel].dropna().astype(str).tolist())

if __name__=="__main__":
    main()
