"""
AI ì„¤ë¬¸ ëŒ€ì‹œë³´ë“œ (2025â€‘07â€‘15 Final)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- ì—…ë¡œë“œ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ CSV ìë™ ë¡œë“œ
- ì»¬ëŸ¼ëª… ì •ê·œí™”(NFKCÂ·ê´„í˜¸ ì œê±°) â†’ KeyError ë°©ì§€
- ìë™ íƒ€ì… ì¶”ë¡  + ì‚¬ìš©ì ìˆ˜ì •
- ë‹¤ì¤‘ ì„ íƒ Topâ€‘10 + ê¸°íƒ€, Bar+Pie
- WordCloud í¬ê¸° ìŠ¬ë¼ì´ë”, ë¯¼ê° ì»¬ëŸ¼ ì œì™¸
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Imports â”€â”€â”€â”€â”€â”€â”€â”€â”€
import streamlit as st, pandas as pd, plotly.express as px
import koreanize_matplotlib, re, io, base64, os, pathlib, tempfile, urllib.request, unicodedata
from collections import Counter; import matplotlib.pyplot as plt
from matplotlib import font_manager; from wordcloud import WordCloud

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Korean Font â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_font()->str:
    for p in ["/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
              "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc"]:
        if os.path.exists(p): return p
    url=("https://raw.githubusercontent.com/google/fonts/main/"
         "ofl/nanumgothic/NanumGothic-Regular.ttf")
    tmp=pathlib.Path(tempfile.gettempdir())/"NanumGothic.ttf"
    if not tmp.exists(): urllib.request.urlretrieve(url,tmp)
    return str(tmp)

FONT=get_font()
plt.rcParams["font.family"]=font_manager.FontProperties(fname=FONT).get_name()
def kplt(fig): return fig.update_layout(font=dict(family="Nanum Gothic, sans-serif"))
px.defaults.template="plotly_white"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Constants â”€â”€â”€â”€â”€â”€â”€â”€â”€
COLUMN_TYPES={"timestamp":"íƒ€ì„","email":"ì´ë©”ì¼","phone":"ì „í™”","name":"ì´ë¦„",
    "student_id":"í•™ë²ˆ","numeric":"ìˆ«ì","single_choice":"ë‹¨ì¼ì„ íƒ","multiple_choice":"ë‹¤ì¤‘ì„ íƒ",
    "linear_scale":"ì²™ë„","text_short":"ë‹¨ë‹µ","text_long":"ì¥ë¬¸","url":"URL","other":"ê¸°íƒ€"}
SENSITIVE_TYPES={"email","phone","student_id","url","name"}
SEP=r"[;,ï¼|]" ; TOK_RGX=re.compile(r"[ê°€-í£]{2,}")
STOP={'ì€','ëŠ”','ì´','ê°€','ì„','ë¥¼','ì˜','ì—','ì™€','ê³¼'}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Util â”€â”€â”€â”€â”€â”€â”€â”€â”€
def normalize(col:str)->str:
    col=unicodedata.normalize("NFKC",col)          # ì „ê°/ë°˜ê° í†µí•©
    col=re.sub(r"\s*\(.*?\)\s*$","",col)           # ê´„í˜¸ ì„¤ëª… ì œê±°
    col=re.sub(r"\s+"," ",col)                     # ë‹¤ì¤‘ ê³µë°± ì œê±°
    return col.strip()

def detect_choice(s:pd.Series)->str:
    s=s.dropna().astype(str)
    if pd.to_numeric(s,errors='coerce').notna().all(): return "numeric"
    if (s.str.contains(SEP)).mean()>0.2: return "multiple_choice"
    if s.nunique()<max(20,len(s)*0.5): return "single_choice"
    return "other"

def wc_base64(text,w,h):
    wc=WordCloud(font_path=FONT,background_color="white",width=w,height=h,max_words=100).generate(text)
    buf=io.BytesIO(); plt.imshow(wc); plt.axis("off"); plt.tight_layout(pad=0)
    plt.savefig(buf,format="png",bbox_inches="tight"); plt.close()
    return "data:image/png;base64,"+base64.b64encode(buf.getvalue()).decode()

def tokenize(t): return TOK_RGX.findall(t)
def freq(tokens,n=20): return Counter([x for x in tokens if x not in STOP]).most_common(n)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Streamlit UI â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config("AI ì„¤ë¬¸ ëŒ€ì‹œë³´ë“œ","ğŸ¤–",layout="wide")
with st.sidebar:
    auto=st.checkbox("âš™ï¸ ì»¬ëŸ¼ ìë™ ì¶”ë¡ ",True)
    wc_w=st.slider("WordCloud í­(px)",400,1000,600,50)
    wc_h=st.slider("WordCloud ë†’ì´(px)",200,600,300,50)

file=st.file_uploader("CSV ì—…ë¡œë“œ",type="csv")
if file is None:
    default=pathlib.Path("ë‚˜ì— ëŒ€í•´ í‚¤ì›Œë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”!(ì‘ë‹µ)ì˜ ì‚¬ë³¸.csv")
    if default.exists():
        file=open(default,"rb")
        st.info(f"ğŸ“‚ ê¸°ë³¸ íŒŒì¼ '{default.name}' ë¡œë“œë¨")
    else:
        st.warning("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ê¸°ë³¸ íŒŒì¼ì„ í”„ë¡œì íŠ¸ í´ë”ì— ë‘ì„¸ìš”.")
        st.stop()

df=pd.read_csv(file)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Column Normalization â”€â”€â”€â”€â”€â”€â”€â”€â”€
df.columns=[normalize(c) for c in df.columns]

# ì„¸ì…˜ configs ì¤€ë¹„
if "configs" not in st.session_state: st.session_state.configs={}
cfg=st.session_state.configs

# ìƒˆ ì»¬ëŸ¼ ìë™ ì¶”ë¡ 
for col in df.columns:
    if col not in cfg:
        if auto:
            t=detect_choice(df[col])
            if t in {"other","text_short","text_long"}:
                mlen=df[col].astype(str).str.len().dropna().max()
                t="text_short" if mlen and mlen<50 else "text_long"
            cfg[col]=t
        else:
            cfg[col]="other"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì¶”ë¡  ê²°ê³¼ ìˆ˜ì • UI â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.expander("ğŸ—‚â€¯ì¶”ë¡  ê²°ê³¼ í™•ì¸ & ìˆ˜ì •",False):
    st.dataframe(pd.DataFrame({"ì»¬ëŸ¼":cfg.keys(),"íƒ€ì…":[COLUMN_TYPES[v] for v in cfg.values()]}),
                 use_container_width=True)
    c1,c2=st.columns(2)
    for i,col in enumerate(df.columns):
        with (c1 if i%2==0 else c2):
            current=cfg.get(col,"other")
            cfg[col]=st.selectbox(col,list(COLUMN_TYPES.keys()),
                                  index=list(COLUMN_TYPES).index(current),
                                  format_func=lambda x:COLUMN_TYPES[x],
                                  key=f"type_{col}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Navigation â”€â”€â”€â”€â”€â”€â”€â”€â”€
page=st.radio("ë©”ë‰´",["ê°œìš”","í†µê³„","í…ìŠ¤íŠ¸"],horizontal=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. ê°œìš” â”€â”€â”€â”€â”€â”€â”€â”€â”€
if page=="ê°œìš”":
    st.subheader("ğŸ“Š ì „ì²´ ê°œìš”")
    st.metric("ì‘ë‹µ ìˆ˜",len(df)); st.metric("ë¬¸í•­ ìˆ˜",len(df.columns))
    compl=(df.notna().sum().sum())/(len(df)*len(df.columns))*100
    st.metric("í‰ê·  ì™„ë£Œìœ¨",f"{compl:.1f}%")
    resp=(df.notna().sum()/len(df)*100).sort_values()
    st.plotly_chart(kplt(px.bar(x=resp.values,y=resp.index,orientation="h",
                    labels={'x':'ì‘ë‹µë¥ (%)','y':'ë¬¸í•­'})),use_container_width=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. í†µê³„ â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif page=="í†µê³„":
    st.subheader("ğŸ“ˆ ì„ íƒí˜•Â·ì²™ë„ ë¶„ì„")
    for col,t in cfg.items():
        if col not in df.columns: continue
        if t not in {"single_choice","multiple_choice","linear_scale","numeric"}: continue
        st.markdown(f"#### {col} ({COLUMN_TYPES[t]})")
        s=df[col].dropna().astype(str)

        if t=="multiple_choice":
            s=s.str.split(SEP,expand=True).stack().str.strip()

        if t in {"linear_scale","numeric"}:
            nums=pd.to_numeric(s,errors="coerce").dropna()
            st.metric("í‰ê· ",f"{nums.mean():.2f}")
            st.plotly_chart(kplt(px.histogram(nums,nbins=10)),use_container_width=True)

        else:  # single / multiple
            cnt=s.value_counts()
            # Topâ€‘10 + ê¸°íƒ€
            if len(cnt)>10:
                top10=cnt.head(10); others=cnt.iloc[10:].sum()
                cnt_bar=top10
                cnt_pie=top10.append(pd.Series({"ê¸°íƒ€":others}))
            else:
                cnt_bar=cnt_pie=cnt

            c1,c2=st.columns(2)
            with c1:
                st.plotly_chart(kplt(px.bar(
                    x=cnt_bar.values,y=cnt_bar.index,orientation="h",
                    labels={'x':'ë¹ˆë„','y':'í•­ëª©'})),use_container_width=True)
            with c2:
                st.plotly_chart(kplt(px.pie(
                    cnt_pie,values=cnt_pie.values,names=cnt_pie.index,hole=.35)),
                    use_container_width=True)
        st.divider()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. í…ìŠ¤íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€
else:
    st.subheader("ğŸ“ í…ìŠ¤íŠ¸ ë¶„ì„")
    for col,t in cfg.items():
        if col not in df.columns: continue
        if t not in {"text_short","text_long"} or t in SENSITIVE_TYPES: continue
        st.markdown(f"##### {col}")
        texts=[str(x) for x in df[col].dropna() if str(x).strip()]
        if not texts:
            st.info("ì‘ë‹µ ì—†ìŒ"); continue
        tokens=[z for tx in texts for z in tokenize(tx)]
        top=freq(tokens)
        if top:
            words,counts=zip(*top)
            st.plotly_chart(kplt(px.bar(x=counts,y=words,orientation="h")),use_container_width=True)
            st.image(wc_base64(' '.join(tokens),wc_w,wc_h),use_container_width=True)
        st.divider()
